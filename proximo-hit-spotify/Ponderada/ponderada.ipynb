{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiro, vamos realizar a importação de todas as bibliotecas que usaremos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import KFold, train_test_split, RandomizedSearchCV, GridSearchCV, cross_val_predict, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, make_scorer\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, Lasso\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_iris\n",
    "from scipy.stats import uniform, randint, loguniform\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, vamos importar nossos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('../test.csv')\n",
    "df = pd.read_csv('../train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None) # Configuracao para mostrar todas as colunas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entendendo o significado de todas as colunas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É de extrema importância entender todas as colunas, por isso, vamos copiar e colar o significado delas:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- track_id: O ID único de cada música\n",
    "    \n",
    "- artists: Nome dos(as) artistas que performaram a música, separados por ';'\n",
    "    \n",
    "- album_name: Nome do álbum no qual aparece a música\n",
    "    \n",
    "- track_name: Nome da música\n",
    "    \n",
    "- duration_ms: A duração da música em milissegundos\n",
    "    \n",
    "- explicit: Boolean indicando se a música possui conteúdo explícito\n",
    "    \n",
    "- danceability: Descreve quanto uma música é \"dançante\" (0.0 = menos dançante, 1.0 = mais dançante)\n",
    "    \n",
    "- energy: Representa a intensidade e atividade de uma música (0.0 = baixa energia, 1.0 = alta energia)\n",
    "    \n",
    "- key: A tonalidade musical da faixa mapeada usando a notação padrão de Classe de Altura (12 notas musicais)\n",
    "    \n",
    "- loudness: Nível geral de volume da faixa em decibéis (dB)\n",
    "    \n",
    "- mode: Indica a modalidade (maior ou menor) da faixa\n",
    "    \n",
    "- speechiness: Detecta a presença de palavras faladas na faixa\n",
    "    \n",
    "- acousticness: Medida de confiança sobre se a faixa é acústica (0,0 = não acústica, 1,0 = altamente acústica)\n",
    "    \n",
    "- instrumentalness: Prediz se uma faixa contém vocais (0,0 = contém vocais, 1,0 = instrumental)\n",
    "    \n",
    "- liveness: Detecta a presença de uma audiência na gravação (0,0 = gravação em estúdio, 1,0 = performance ao vivo)\n",
    "    \n",
    "- valence: Mede a positividade musical transmitida por uma faixa (0,0 = negativa, 1,0 = positiva)\n",
    "    \n",
    "- tempo: Tempo estimado da faixa em batidas por minuto (BPM)\n",
    "    \n",
    "- time_signature: Assinatura de tempo estimada da faixa (de 3 a 7)\n",
    "    \n",
    "- track_genre: O gênero da música\n",
    "    \n",
    "- popularity_target: Boolean indicando se a música é popular ou não"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizando a análise das colunas, fiquei em dúvida sobre a diferença entre a coluna 'tempo' e 'time_signature'. Por isso, realizei uma análise mais profunda no significado delas:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* tempo (Batidas por minuto):\n",
    "   * O tempo representa a velocidade ou ritmo de uma faixa, medido em batidas por minuto (BPM).\n",
    "   * O tempo médio é de cerca de 122 BPM, o que representa um ritmo moderado e enérgico.\n",
    "   * O tempo mínimo é 0 BPM (o que pode indicar dados ausentes ou faixas muito lentas), e o máximo é cerca de 223 BPM (muito rápido).\n",
    "\n",
    "* time_signature (Fórmula de compasso):\n",
    "   * A fórmula de compasso representa a estrutura rítmica de uma faixa, indicando quantas batidas existem em cada compasso e qual valor de nota representa uma batida.\n",
    "   * Os valores geralmente variam de 3 a 7, sendo 4 o mais comum (representando o compasso 4/4, que é padrão em muitos gêneros).\n",
    "   * A partir das estatísticas, podemos ver que a mediana e os percentis 25 e 75 são 4, confirmando que o compasso 4/4 é realmente o mais comum.\n",
    "   * O mínimo de 0 pode indicar dados ausentes ou fórmulas de compasso não convencionais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiro dou uma olhada por cima dos dados apenas para entender quais colunas são númericas e categóricas. Também tenho a intenção de ver elas como dados reais e por isso chamo o comando `df.head(3)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora partindo para uma análise mais profunda das colunas numéricas, começo com uma análise da estatística descritiva de cada coluna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com o output acima, já é possível observar que valores iguais a 0 em 'tempo' e 'time_signature' provavelmente são missing values. Chegamos a essa conclusão porque músicas com 0 BPM não existem, mesmo muito lentas. E 'time_sigture' já comenta na definição das colunas que os valores vão de 3 a 7, ou seja, 0 é incorreto. Não realizamos a correção desses valores faltantes nesse exato momento, mas em breve voltaremos com eles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploração e Visualização dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, na intenção de entender os dados e descobrir padrões, vamos realizar uma exploração e visualização dos dados! Para isso, vamos utilizar bibliotecas como Matplot e Seaborn. Nossa missão aqui é descobrir padrões, correlações e tendências nos dados. Vamos usar visualizações eficazes para comunicar os insights e justificar nossas futuras escolhas de features e modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo um estilo para nossos graficos e alterando o tamanho padrão das figuras geradas pelo Matplotlib\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para o começo da nossa análise, é importante saber a quantidade de músicas que são populares ou não e saber como está a distribuição entre elas. No gráfico gerado a seguir, é possível observar que existe uma divisão bem harmoniosa entre músicas populares e não populares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='popularity_target', data=df)\n",
    "plt.title('Distribution of Song Popularity')\n",
    "plt.xlabel('Popularity (0: Not Popular, 1: Popular)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partindo com nossa análise, vamos agora observar nossas variáveis numéricas e a relação entre elas. O Heatmap é um gráfico perfeito para isso que demonstra as relações entre as colunas. Resumindo bastante funciona da forma a seguir: \n",
    "\n",
    "Os valores de correlação variam de -1 a 1:\n",
    "\n",
    "- **+1**: Correlação positiva perfeita. À medida que uma variável aumenta, a outra também aumenta.\n",
    "- **-1**: Correlação negativa perfeita. À medida que uma variável aumenta, a outra diminui.\n",
    "- **0**: Nenhuma correlação. As duas variáveis não afetam uma à outra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = ['duration_ms', 'danceability', 'energy', 'key', 'loudness', 'speechiness', \n",
    "                      'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(df[numerical_features].corr(), annot=True, cmap='coolwarm', linewidths=0.5)\n",
    "plt.title('Correlation Heatmap of Numerical Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizando a análise do Heatmap acima, é possível identificar alguns padrões importantes sobre nossa base de dados.\n",
    "\n",
    "1. Correlação forte entre 'energy' e 'loudness': Existe uma correlação positiva forte (0.76) entre 'energy' e 'loudness', indicando que músicas mais enérgicas tendem a ser mais altas.\n",
    "\n",
    "2. Correlação negativa entre 'acousticness' e 'energy': Há uma forte correlação negativa (-0.73) entre 'acousticness' e 'energy', sugerindo que músicas mais acústicas tendem a ser menos enérgicas.\n",
    "\n",
    "3. Correlação negativa entre 'acousticness' e 'loudness': Similarmente, existe uma correlação negativa moderada (-0.59) entre 'acousticness' e 'loudness', indicando que músicas acústicas tendem a ser menos altas.\n",
    "\n",
    "4. Correlação positiva entre 'danceability' e 'valence': Há uma correlação positiva moderada (0.48) entre 'danceability' e 'valence', sugerindo que músicas mais dançantes tendem a ter um tom emocional mais positivo.\n",
    "\n",
    "5. Correlação negativa entre 'instrumentalness' e 'loudness': Observa-se uma correlação negativa moderada (-0.43) entre 'instrumentalness' e 'loudness', indicando que músicas mais instrumentais tendem a ser menos altas.\n",
    "\n",
    "6. Pouca correlação com 'duration_ms': A 'duration_ms' tem correlações fracas com a maioria das outras características, sugerindo que o comprimento da música não está fortemente relacionado com suas outras propriedades acústicas.\n",
    "\n",
    "7. Correlações fracas com 'key': A 'key' tem correlações muito fracas com outras características, indicando que não há uma relação forte entre a tonalidade e outros aspectos musicais neste conjunto de dados.\n",
    "\n",
    "8. Correlações moderadas com 'valence': A 'valence' tem correlações moderadas positivas com 'danceability' (0.48) e 'energy' (0.26), sugerindo que músicas mais positivas tendem a ser mais dançantes e enérgicas.\n",
    "\n",
    "9. Pouca correlação entre 'tempo' e outras características: O 'tempo' da música tem correlações relativamente fracas com outras características, com a mais forte sendo com 'energy' (0.24).\n",
    "\n",
    "10. Correlação fraca entre 'speechiness' e outras características: 'Speechiness' tem correlações geralmente fracas com outras características, com a mais notável sendo com 'liveness' (0.21).\n",
    "\n",
    "11. 'Liveness' tem correlações fracas: A característica 'liveness' não mostra correlações fortes com nenhuma outra característica, sugerindo que é relativamente independente das outras propriedades musicais.\n",
    "\n",
    "Saber desses padrão será importante para quando começarmos a selecionar as features para o treinamento do nosso modelo! Porque aqui é possível observar que alguns colunas estão extremamente ligadas com outras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, queremos entender como diferentes características musicais se relacionam com a popularidade das músicas. Por isso, vamos criar alguns gráficos para realizar essa visualização.\n",
    "\n",
    "Com essa análise, vamos identificar quais características musicais têm maior influência na popularidade de uma música."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "features = ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', 'instrumentalness']\n",
    "for i, feature in enumerate(features):\n",
    "    sns.boxplot(x='popularity_target', y=feature, data=df, ax=axes[i//3][i%3])\n",
    "    axes[i//3][i%3].set_title(f'{feature.capitalize()} by Popularity')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observando o gráfico acima, conseguimos ter alguns insights.\n",
    "\n",
    "1. Danceability (Dançabilidade):\n",
    "\n",
    "Há uma ligeira tendência de músicas populares (1) terem maior dançabilidade.\n",
    "A diferença é pequena, mas notável, o que sugere que músicas mais dançantes têm uma probabilidade um pouco maior de serem populares.\n",
    "\n",
    "2.Instrumentalness (Instrumentalidade):\n",
    "\n",
    "Músicas populares tendem a ter menor instrumentalidade.\n",
    "Isso sugere que músicas com vocais são geralmente mais populares do que músicas puramente instrumentais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, para entender quais gêneros proporcionam mais sucessos às músicas, vamos criar um gráfico para visualizar os 10 melhores gêneros em termos de músicas populares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_genres = df['track_genre'].value_counts().nlargest(10)\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=top_genres.index, y=top_genres.values)\n",
    "plt.title('Top 10 Genres by Count')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "sns.scatterplot(data=df, x='energy', y='danceability', hue='popularity_target', palette='viridis')\n",
    "plt.title('Energy vs. Danceability (Colored by Popularity)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Análisando o gráfico acima, podemos observar que a popularidade não parece ser exclusivamente determinada por altos níveis de energia e dançabilidade, já que músicas populares existem em diversos níveis de energia e dançabilidade, sugerindo que outros fatores também influenciam a popularidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(data=df, x='duration_ms', bins=50, kde=True)\n",
    "plt.title('Distribution of Song Durations')\n",
    "plt.xlabel('Duration (ms)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observando a duração das músicas, podemos observar que há uma concentração muito alta de músicas com duração menor. Também observamos que existem músicas com durações extremamente longas. Estes podem ser álbuns inteiros, performances ao vivo, ou erros nos dados.\n",
    "\n",
    "- A assimetria da distribuição pode afetar análises estatísticas, sendo necessário considerar transformações ou métodos robustos. Em breve voltaremos nesse tópico ao tratar os dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Já o gráfico de barras empilhadas abaixo apresenta uma comparação visual da proporção de conteúdo explícito entre músicas populares e não populares "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explicit_by_popularity = df.groupby('popularity_target')['explicit'].value_counts(normalize=True).unstack()\n",
    "explicit_by_popularity.plot(kind='bar', stacked=True)\n",
    "plt.title('Proportion of Explicit Content by Popularity')\n",
    "plt.xlabel('Popularity')\n",
    "plt.ylabel('Proportion')\n",
    "plt.legend(title='Explicit', loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observando o gráfico acima, podemos observar que:\n",
    "\n",
    "1. A maioria das músicas, tanto populares quanto não populares, não contém conteúdo explícito.\n",
    "2. Há uma ligeira tendência de músicas populares terem uma proporção um pouco maior de conteúdo explícito em comparação com as não populares.\n",
    "3. A presença de conteúdo explícito não parece ser um fator determinante para a popularidade de uma música, dada a pequena diferença observada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora para fechar nossa análise, vamos comparar a distribuição da duração das músicas entre as categorias de popularidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxenplot(x='popularity_target', y='duration_ms', data=df)\n",
    "plt.title('Song Duration Distribution by Popularity')\n",
    "plt.xlabel('Popularity (0: Not Popular, 1: Popular)')\n",
    "plt.ylabel('Duration (ms)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observando o gráfico acima, vemos que:\n",
    "\n",
    "1. As medianas de duração para músicas populares e não populares são muito semelhantes, sugerindo que a duração por si só não é um forte indicador de popularidade.\n",
    "2. A dispersão (representada pelo tamanho das caixas) é ligeiramente menor para músicas populares, indicando uma maior consistência na duração dessas faixas.\n",
    "3. Existem muitos outliers em ambas as categorias, representando músicas com durações excepcionalmente longas.\n",
    "4. As músicas populares parecem ter menos outliers extremos em comparação com as não populares, especialmente na faixa de duração mais longa.\n",
    "5. A maioria das músicas, independentemente da popularidade, tem duração dentro de um intervalo relativamente estreito, como evidenciado pelo tamanho das caixas do boxplot.\n",
    "6. Há uma leve tendência de músicas populares terem durações um pouco mais curtas, observável pela posição ligeiramente inferior da caixa para músicas populares."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os insights mais importantes que encontramos em nossa análise incluem: a ligeira tendência de músicas populares terem maior energia e dançabilidade; a predominância de conteúdo não explícito em ambas as categorias de popularidade, com uma sutil inclinação para mais conteúdo explícito em músicas populares; e a observação de que a duração das músicas não é um forte indicador de popularidade, embora músicas populares tendam a ter durações mais consistentes. Além disso, notamos correlações significativas entre certas características musicais, como a relação positiva entre energia e volume (loudness), e negativa entre acústica e energia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ainda é muito cedo para entrarmos na escolha das features para nosso modelo, mas já é possível observar que não existe uma coluna em específica que determina a popularidade das músicas, com isso, é bastante provável que vamos utilizar todas as colunas para treinar nosso modelo, excluindo apenas as colunas de identificação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formulação de Hipóteses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hipótese 01: Influência da dançabilidade na era do TikTok\n",
    "\n",
    "Com a popularização do TikTok, onde coreografias virais são frequentes, músicas mais dançantes podem ter maior probabilidade de se tornarem populares. Esta hipótese sugere uma correlação positiva entre a dançabilidade de uma música e sua popularidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(2, 2, 1)\n",
    "sns.boxplot(x='popularity_target', y='danceability', data=df)\n",
    "plt.title('Dançabilidade vs. Popularidade')\n",
    "plt.xlabel('Popularidade (0: Não Popular, 1: Popular)')\n",
    "plt.ylabel('Dançabilidade')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É possível observar que a média de músicas dançantes é um pouco mais alto para músicas populares, mas a diferença não é tão grande assim, logo, não indica extrema importância se a música é dançante ou não para ela ser popular."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hipótese 02: Conteúdo explícito em músicas de temática triste\n",
    "\n",
    "Músicas categorizadas como \"sad\" ou emocionalmente intensas podem ter uma maior tendência a conter conteúdo explícito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(2, 2, 2)\n",
    "sad_genres = ['sad', 'melancholic', 'emotional']  # Ajuste conforme necessário\n",
    "df['is_sad'] = df['track_genre'].isin(sad_genres)\n",
    "sns.barplot(x='is_sad', y='explicit', data=df)\n",
    "plt.title('Conteúdo Explícito em Músicas Tristes vs. Outras')\n",
    "plt.xlabel('Gênero Triste')\n",
    "plt.ylabel('Proporção de Conteúdo Explícito')\n",
    "df = df.drop(columns='is_sad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É possível observar que o conteúdo explícito está extremamente presente em músicas classificadas como 'sad', 'melancholic' ou 'emotional'. Comprovando nossa hipótese."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hipótese 03: Popularidade de músicas com temática melancólica\n",
    "\n",
    "Músicas classificadas como 'sad' estão entre as mais populares, principalmente porque hoje a depressão é o problema do século."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_genres = df['track_genre'].value_counts().nlargest(10)\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=top_genres.index, y=top_genres.values)\n",
    "plt.title('Top 10 Genres by Count')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É possível ver que o gênero 'sad' é o segundo gênero com maior sucesso de músicas populares. Comprovando nossa hipótese."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hipótese 04: Relação inversa entre instrumentalidade e popularidade\n",
    "\n",
    "Músicas com alto grau de instrumentalidade (pouco ou nenhum vocal) podem tender a ser menos populares, possivelmente devido à preferência do público mainstream por músicas com letras e vozes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(2, 2, 4)\n",
    "sns.boxplot(x='popularity_target', y='instrumentalness', data=df)\n",
    "plt.title('Instrumentalidade vs. Popularidade')\n",
    "plt.xlabel('Popularidade (0: Não Popular, 1: Popular)')\n",
    "plt.ylabel('Instrumentalidade')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É possível observar que existem músicas populares e que são instrumentais, mas, em maioria, elas são classificadas como não populares. Comprovando nossa hipótese."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpeza e Tratamento de Valores Nulos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamento de valores duplicados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fazer a limpeza de valores duplicados é importantes pois valores duplicados podem prejudicar no aprendizado do nosso algoritmo. Para realizar a limpeza, vamos primeiro checar se existem valores duplicados e caso existirem, vamos excluir todos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicated_values = df[df.duplicated()]\n",
    "print(len(duplicated_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver acima, não existem valores duplicados. Assim, seguiremos com nossa análise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamento de missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing values são valores = null\n",
    "\n",
    "É importante verificar a existência deles e resolver os valores faltantes caso existam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver acima, também não existem valores faltantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, vamos verificar valores que são iguais a 0. Como identificamos lá no começo desse notebook, já sabemos de alguns valores que não deveriam estar iguais a 0. Também vamos procurar por novos valores iguais a 0 e que não deveriam estar assim, caso existam, vamos resolver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_count = (df == 0).sum()\n",
    "print(zero_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver acima, as colunas 'time_signature' e 'tempo' possuem valores iguais a 0 e elas não deveriam estar assim:\n",
    "\n",
    "1. Tempo:\n",
    "\n",
    "- Representa a velocidade da música em batidas por minuto (BPM).\n",
    "- Um valor 0 significaria que não há batidas, o que é musicalmente impossível.\n",
    "- Tempos típicos variam de cerca de 60 BPM (lento) a 200 BPM (muito rápido).\n",
    "\n",
    "\n",
    "2. Time signature (fórmula de compasso):\n",
    "\n",
    "- Indica quantas batidas há por compasso e qual nota representa uma batida.\n",
    "- É escrita como uma fração, por exemplo, 4/4 ou 3/4.\n",
    "- Um valor 0 não faria sentido, pois implicaria em nenhuma batida por compasso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['time_signature'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['tempo'].describe(), df['tempo'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para resolver esses 2 problemas, vamos: \n",
    "\n",
    "- Substituir os valores de 'time_signature' pela moda, que é 4\n",
    "- Substituir os valores de 'tempo' pela mediana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempo_median = df['tempo'].median()\n",
    "df_treating_data = df.copy()\n",
    "df_treating_data['tempo'] = df_treating_data['tempo'].replace(0,tempo_median)\n",
    "df_treating_data['time_signature'] = df_treating_data['time_signature'].replace(0,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identificação de outliers e correção"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As colunas que vamos visualizar e depois tratar os outliers são as colunas: 'duration_ms', 'loudness' e 'tempo'.\n",
    "\n",
    "Realizei a escolha dessas três colunas porque todas as outras colunas numéricas se constituem de valores que vâo de 0 a 1. Algumas até possuem outliers mas são features importantes e que quero manter para preservar a pureza dos dados em features que vão de 0 a 1. Mais tarde, vamos minimizar os impactos que esses outliers podem causar com o standardScaler\n",
    "\n",
    "Agora partindo para a identificação dos outliers que escolhemos, vamos começar visualizando em boxplot os possíveis outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=df_treating_data, y='duration_ms')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observando o gráfico acima, é possívei ver que 'duration_ms' possui vários outliers, vamos guardar essa informação e em breve corrigir eles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora fazendo a análise dos outliers de 'loudness', vamos desenhar outro boxplot para realizar essa visualização:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=df_treating_data, y='loudness')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora fazendo a análise dos outliers de 'tempo', vamos desenhar outro boxplot para realizar essa visualização:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=df_treating_data, y='tempo')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sabendo dos outliers que 'duration_ms', 'loudness' e 'tempo' possuem, vamos agora partir para a correção deles.\n",
    "\n",
    "Para os outliers de 'loudness' e 'tempo', decidi manter eles do jeito que estão. Pelas mesmas que citei acima, sobre as colunas que vão de 0 a 1. \n",
    "\n",
    "Como essas duas colunas representam caracteristicas específicas da música em questão e também podem representar escolhas específicas do artista que a fez, acho importante manter esses outliers do jeito que estão.\n",
    "\n",
    "---\n",
    "\n",
    "Já para os outliers de 'duration_ms', vamos agora tentar três medidas diferentes para corrigi-los:\n",
    "\n",
    "1. Vamos manter eles intocáveis.\n",
    "2. Vamos excluir todos os outliers\n",
    "3. Vamos aplicar uma transformação logarítmica.\n",
    "\n",
    "A transformação logarítmica ajuda a lidar com outliers (valores extremos) e dados distorcidos ao comprimir a amplitude dos valores, especialmente os números grandes. Isso faz com que valores extremos se tornem menos extremos, enquanto ainda preserva as diferenças relativas entre os dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de tomar essas três medidas, vamos excluir algumas colunas que não serão importantes para o treinamento do nosso modelo, essas colunas são: 'track_id', 'track_unique_id', 'artists', 'album_name' e 'track_name'.\n",
    "\n",
    "- track_id: Usado apenas para identificação de uma música em questão, por isso, não é importante para nosso futuro modelo.\n",
    "- track_unique_id: Também usado apenas para identificação.\n",
    "- artists: Poderia ser um dado importante caso nossa base de dados classificasem o nível de fama de cada artista, pois artistas famosos tendem a gerar músicas populares com mais facilidade. Como nossa base de dados não contém isso, vamos excluir essa coluna porque na situação que está, essa coluna é usada apenas para identificação.\n",
    "- album_name: Como nossa base de dados não contém também uma coluna classificando o nível de popularidade do album em questão, não vamos estar utilizando essa informação.\n",
    "- track_name: Usado apenas para identificação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_treating_data = df_treating_data.drop(columns=['track_unique_id', 'track_id', 'artists', 'album_name', 'track_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com essas alterações feitas, agora vamos tomar as três medidas para realizar a correção dos outliers de 'durations_ms'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Primeiro, vamos tomar a medida em que excluímos todos os outliers de 'duration_ms'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df_treating_data['duration_ms'].quantile(0.25)\n",
    "Q3 = df_treating_data['duration_ms'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "df_no_duration_outliers = df_treating_data.copy()\n",
    "\n",
    "df_no_duration_outliers = df_no_duration_outliers[(df_no_duration_outliers['duration_ms'] >= lower_bound) & (df_no_duration_outliers['duration_ms'] <= upper_bound)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Segundo, vamos aplicar a transformação logarítmica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando uma copia para nossa segunda medida com os outliers\n",
    "df_duration_log = df_treating_data.copy()\n",
    "\n",
    "# fazendo a transformacao logaritma\n",
    "df_duration_log['duration_log'] = np.log1p(df_duration_log['duration_ms'])\n",
    "\n",
    "# excluindo a coluna de duracao normal porque nao vamos utilizar ela nessa base de dados\n",
    "df_duration_log = df_duration_log.drop(columns=['duration_ms'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora é possível observar que estamos com três base de dados:\n",
    "\n",
    "1. df_treating_data: Contém os outliers de 'duration_ms' sem alterações\n",
    "2. df_no_duration_outliers: Não contém nenhum outlier de 'duration_ms'\n",
    "3. df_duration_log: Contém os outliers mas com a transformação log aplicada em todos.\n",
    "\n",
    "Agora, seguiremos com esses 3 modelos até o treinamento do nosso modelo, onde veremos qual base de dados resultará um melhor resultado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Codificação de Variáveis Categóricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplique técnicas apropriadas de codificação para transformar variáveis categóricas em formatos utilizáveis em modelos preditivos, garantindo que a informação essencial não seja perdida no processo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, entramos na etapa de codificar as variáveis categóricas. As únicas 2 colunas que não são numéricas e precisar sem codificadas, são 'explicit' que é uma coluna boolean e 'track_genre' que é uma coluna categórica. \n",
    "\n",
    "Para garantir que não vamos perder as informações essenciais nessa etapa, vamos codificar as variáveis de 'track_genre' com um método chamado Target Encode. \n",
    "\n",
    "Já a coluna 'explicit', por ser uma coluna boolean, para codifica-lá, basta transformar os valores em valores int. Faremos isso abaixo.\n",
    "\n",
    "É importante lembrar que, como temos 3 base de dados, vamos codificar as colunas de cada uma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_treating_data['explicit'] = df_treating_data['explicit'].astype(int)\n",
    "df_no_duration_outliers['explicit'] = df_no_duration_outliers['explicit'].astype(int)\n",
    "df_duration_log['explicit'] = df_duration_log['explicit'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora abaixo, criamos a função para codificar nossa coluna 'track_genre'. \n",
    "\n",
    "A escolha do Target Encode foi feita porque enfrentamos o desafio de lidar com a variável categórica 'track_genre', que possui alta cardinalidade (114 categorias únicas). Para abordar esse problema de maneira eficaz, implementamos a técnica de Target Encoding.\n",
    "\n",
    "Target Encoding é uma técnica usada para converter variáveis categóricas em valores numéricos. Diferentemente de métodos como mais utilizados como LabelEncoder, o Target Encoding leva em consideração a variável alvo (popularity_target) ao realizar a codificação.\n",
    "\n",
    "1. Para cada categoria na variável categórica (no nosso caso, cada gênero musical), calculamos a média da variável alvo.\n",
    "2. Substituímos cada categoria pelo valor médio calculado.\n",
    "3. Para evitar overfitting, utilizamos uma abordagem de validação cruzada na implementação.\n",
    "\n",
    "Mas por que estamos usando o Target Encoder nesse caso ?\n",
    "\n",
    "1. Alta Cardinalidade: Com 114 gêneros musicais únicos, métodos como One-Hot Encoding criariam um número excessivo de features, potencialmente levando a problemas de dimensionalidade.\n",
    "2. Captura de Informação Relevante: O Target Encoding captura a relação entre cada gênero musical e a popularidade da música, fornecendo uma representação numérica significativa.\n",
    "3. Eficiência Computacional: Reduz a dimensionalidade dos dados sem perder informações cruciais sobre a relação entre gênero e popularidade.\n",
    "4. Tratamento de Categorias Raras: Lida bem com gêneros musicais que aparecem com pouca frequência no dataset.\n",
    "\n",
    "O Target Encoding nos permite transformar a informação categórica dos gêneros musicais em uma representação numérica que preserva e destaca a relação entre gênero e popularidade.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_encode_train(df, column, target, n_splits=5):\n",
    "    encoded = np.zeros(len(df))\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    \n",
    "    encoding_dict = {}\n",
    "    \n",
    "    for train_idx, val_idx in kf.split(df):\n",
    "        target_means = df.iloc[train_idx].groupby(column)[target].mean()\n",
    "        encoded[val_idx] = df[column].iloc[val_idx].map(target_means)\n",
    "        \n",
    "        encoding_dict.update(target_means.to_dict())\n",
    "    \n",
    "    global_mean = df[target].mean()\n",
    "    encoded = np.where(np.isnan(encoded), global_mean, encoded)\n",
    "    \n",
    "    encoding_dict['_global_mean'] = global_mean\n",
    "    \n",
    "    return encoded, encoding_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_encode_test(df, column, encoding_dict):\n",
    "    global_mean = encoding_dict['_global_mean']\n",
    "    return df[column].map(encoding_dict).fillna(global_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_treating_data['track_genre_encoded'], encoding_dict = target_encode_train(df_treating_data, 'track_genre', 'popularity_target')\n",
    "\n",
    "# Verificação dos resultados\n",
    "print(df_treating_data[['track_genre', 'track_genre_encoded', 'popularity_target']].head(10))\n",
    "print(\"\\nCorrelação entre 'track_genre_encoded' e 'popularity_target':\")\n",
    "print(df_treating_data['track_genre_encoded'].corr(df['popularity_target']))\n",
    "df_treating_data = df_treating_data.drop(columns='track_genre')\n",
    "\n",
    "# Aqui vamos salvar o encoding_dict para usarmos mais tarde quando for para codificar o df_test\n",
    "joblib.dump(encoding_dict, 'category_encoding.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_duration_outliers['track_genre_encoded'], encoding_dict_no_duration_outliers = target_encode_train(df_no_duration_outliers, 'track_genre', 'popularity_target')\n",
    "\n",
    "# Verificação dos resultados\n",
    "print(df_no_duration_outliers[['track_genre', 'track_genre_encoded', 'popularity_target']].head(10))\n",
    "print(\"\\nCorrelação entre 'track_genre_encoded' e 'popularity_target':\")\n",
    "print(df_no_duration_outliers['track_genre_encoded'].corr(df['popularity_target']))\n",
    "df_no_duration_outliers = df_no_duration_outliers.drop(columns='track_genre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_duration_log['track_genre_encoded'], encoding_dict_log = target_encode_train(df_duration_log, 'track_genre', 'popularity_target')\n",
    "\n",
    "# Verificação dos resultados\n",
    "print(df_duration_log[['track_genre', 'track_genre_encoded', 'popularity_target']].head(10))\n",
    "print(\"\\nCorrelação entre 'track_genre_encoded' e 'popularity_target':\")\n",
    "print(df_duration_log['track_genre_encoded'].corr(df['popularity_target']))\n",
    "df_duration_log = df_duration_log.drop(columns='track_genre')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Análisando os resultados acima, podemos ver que o Target Encoding capturou informações relevantes sobre a relação entre os gêneros musicais e a popularidade, sem criar uma relação perfeita que poderia levar a overfitting.\n",
    "\n",
    "Por exemplo, \"pop\" tem um valor codificado de 0.675627, sugerindo que cerca de 67.56% das músicas pop são populares.\n",
    "\n",
    "Essas informações serão valiosas no momento em que formos treinar os algoritmos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seleção de Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As features que vamos incluir em nosso modelo preditivo são: \n",
    "\n",
    "duration_ms', 'explicit', 'danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'time_signature', 'popularity_target', 'track_genre_encoded'\n",
    "\n",
    "Justificativa para a escolha dessas features:\n",
    "\n",
    "1. duration_ms: Duração da faixa em milissegundos\n",
    "2. explicit: Indicador de conteúdo explícito\n",
    "3. danceability: Quão adequada a faixa é para dançar\n",
    "4. energy: Medida de intensidade e atividade\n",
    "5. key: Tonalidade da faixa\n",
    "6. loudness: Volume geral da faixa em decibéis\n",
    "7. mode: Modalidade da faixa (maior ou menor)\n",
    "8. speechiness: Presença de palavras faladas\n",
    "9. acousticness: Medida de quão acústica é a faixa\n",
    "10. instrumentalness: Predição da ausência de vocais\n",
    "11. liveness: Presença de público na gravação\n",
    "12. valence: Positividade musical da faixa\n",
    "13. tempo: Velocidade ou ritmo estimado em BPM\n",
    "14. time_signature: Fórmula de compasso estimada\n",
    "15. popularity_target: Alvo de popularidade (variável dependente)\n",
    "16. track_genre_encoded: Gênero da faixa (codificado)\n",
    "\n",
    "Justificativa da Seleção\n",
    "\n",
    "1. Características Acústicas: danceability, energy, loudness, acousticness, instrumentalness, valence, e tempo foram incluídas por representarem aspectos fundamentais do som e da percepção musical, que podem influenciar diretamente a popularidade.\n",
    "2. Estrutura Musical: key, mode, e time_signature foram mantidas por fornecerem informações sobre a estrutura musical, que pode afetar a acessibilidade e apelo da faixa.\n",
    "3. Conteúdo: explicit e speechiness foram incluídas por poderem influenciar a recepção e distribuição da música em diferentes plataformas e faixas etárias.\n",
    "4. Experiência de Escuta: duration_ms e liveness foram mantidas por afetarem a experiência de escuta, potencialmente impactando o engajamento do ouvinte.\n",
    "5. Contexto: track_genre_encoded foi incluída por fornecer contexto importante sobre o estilo musical, que pode ser crucial para entender padrões de popularidade em diferentes nichos.\n",
    "6. Alvo: popularity_target é a variável dependente que o modelo tentará prever.\n",
    "\n",
    "- Vale também levantar o ponto de que para prever com a melhor acurácia possível, é importante manter o máximo de colunas porque os dados parecem estar extremamente conectados entre si.\n",
    "\n",
    "Pré-processamento e transformação:\n",
    "\n",
    "1. Para tentar ao máximo garantir o melhor resultado possível, em breve, vamos criar novas base de dados e realizar o escalonamento de todos os valores. (Vale levantar o ponto de que vamos testar todas as bases de dados e escolher o melhor resultado gerado.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construção e Avaliação do Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de selecionar um modelo de Machine Learning, precisamos separar nossos dados entre 'treino', 'validação' e 'teste'. Como estamos trabalhando com três bases de dados, vamos separar os dados para todas elas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os três códigos abaixo, separam o 'popularity_target' do resto da base de dados, assim, podemos treinar nosso algoritmo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df_treating_data = df_treating_data.drop('popularity_target', axis=1)\n",
    "y_df_treating_data = df_treating_data['popularity_target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df_no_duration_outliers = df_no_duration_outliers.drop('popularity_target', axis=1)\n",
    "y_df_no_duration_outliers = df_no_duration_outliers['popularity_target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df_duration_log = df_duration_log.drop('popularity_target', axis=1)\n",
    "y_df_duration_log = df_duration_log['popularity_target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, vamos separar as bases de dados entre 'train', 'validation' e 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primeiro, conjunto de teste\n",
    "X_temp_df_treating_data, X_test_df_treating_data, y_temp_df_treating_data, y_test_df_treating_data = train_test_split(X_df_treating_data, y_df_treating_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Agora, o restante em treino e validação\n",
    "X_train_df_treating_data, X_val_df_treating_data, y_train_df_treating_data, y_val_df_treating_data = train_test_split(X_temp_df_treating_data, y_temp_df_treating_data, test_size=0.25, random_state=42)\n",
    "\n",
    "print(f\"Tamanho do conjunto de treino: {len(X_train_df_treating_data)}\")\n",
    "print(f\"Tamanho do conjunto de validação: {len(X_val_df_treating_data)}\")\n",
    "print(f\"Tamanho do conjunto de teste: {len(X_test_df_treating_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primeiro, conjunto de teste\n",
    "X_temp_df_no_duration_outliers, X_test_df_no_duration_outliers, y_temp_df_no_duration_outliers, y_test_df_no_duration_outliers = train_test_split(X_df_no_duration_outliers, y_df_no_duration_outliers, test_size=0.2, random_state=42)\n",
    "\n",
    "# Agora, o restante em treino e validação\n",
    "X_train_df_no_duration_outliers, X_val_df_no_duration_outliers, y_train_df_no_duration_outliers, y_val_df_no_duration_outliers = train_test_split(X_temp_df_no_duration_outliers, y_temp_df_no_duration_outliers, test_size=0.25, random_state=42)\n",
    "\n",
    "print(f\"Tamanho do conjunto de treino: {len(X_train_df_no_duration_outliers)}\")\n",
    "print(f\"Tamanho do conjunto de validação: {len(X_val_df_no_duration_outliers)}\")\n",
    "print(f\"Tamanho do conjunto de teste: {len(X_test_df_no_duration_outliers)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primeiro, conjunto de teste\n",
    "X_temp_df_duration_log, X_test_df_duration_log, y_temp_df_duration_log, y_test_df_duration_log = train_test_split(X_df_duration_log, y_df_duration_log, test_size=0.2, random_state=42)\n",
    "\n",
    "# Agora, o restante em treino e validação\n",
    "X_train_df_duration_log, X_val_df_duration_log, y_train_df_duration_log, y_val_df_duration_log = train_test_split(X_temp_df_duration_log, y_temp_df_duration_log, test_size=0.25, random_state=42)\n",
    "\n",
    "print(f\"Tamanho do conjunto de treino: {len(X_train_df_duration_log)}\")\n",
    "print(f\"Tamanho do conjunto de validação: {len(X_val_df_duration_log)}\")\n",
    "print(f\"Tamanho do conjunto de teste: {len(X_test_df_duration_log)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como um último teste, em busca do melhor resultado possível, vamos também escalonar nossa base de dados 'df_treating_data' para também testar algoritmos com o escalonamento e decidir entre o melhor resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_df_treating_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df_treating_data_scaled = scaler.transform(X_train_df_treating_data)\n",
    "X_val_df_treating_data_scaled = scaler.transform(X_val_df_treating_data)\n",
    "X_test_df_treating_data_scaled = scaler.transform(X_test_df_treating_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testando os modelos preditivos\n",
    "\n",
    "Agora, com tudo feito e separado, podemos começar a testar os algoritmos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta etapa, vamos testar vários algoritmos e apenas no final tirar nossas conclusões sobre o quais são os melhores, por isso, voltarei a documentar com frequência após essa etapa de testes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier = RandomForestClassifier(random_state=42, n_estimators=500, min_samples_split=2, min_samples_leaf=1,max_features='sqrt',max_depth=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier.fit(X_train_df_treating_data, y_train_df_treating_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_df_treating_data_random_forest = rf_classifier.predict(X_val_df_treating_data)\n",
    "\n",
    "print(classification_report(y_val_df_treating_data, y_pred_df_treating_data_random_forest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier.fit(X_train_df_no_duration_outliers, y_train_df_no_duration_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_df_no_duration_outliers_random_forest = rf_classifier.predict(X_val_df_no_duration_outliers)\n",
    "\n",
    "print(classification_report(y_val_df_no_duration_outliers, y_pred_df_no_duration_outliers_random_forest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier.fit(X_train_df_duration_log, y_train_df_duration_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_df_duration_log_random_forest = rf_classifier.predict(X_val_df_duration_log)\n",
    "\n",
    "print(classification_report(y_val_df_duration_log, y_pred_df_duration_log_random_forest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier.fit(X_train_df_treating_data_scaled, y_train_df_treating_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_df_treating_data_scaled_random_forest = rf_classifier.predict(X_val_df_treating_data_scaled)\n",
    "\n",
    "print(classification_report(y_val_df_treating_data, y_pred_df_treating_data_scaled_random_forest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver acima, o random forest em média nos garante um resultado de 82% de 'accuracy'. O ideial agora, é rodar o .predict na base de testar para garantir que não existe um overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_df_treating_data_scaled_test = rf_classifier.predict(X_test_df_treating_data_scaled)\n",
    "\n",
    "print(classification_report(y_test_df_treating_data, y_pred_df_treating_data_scaled_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver acima, o resultado do 'test' é bem parecido com o resultado do 'val'. O resultado dos 82% de 'acurracy' já são o suficiente para realizar o envio da tarefa mas vamos testar mais alguns modelos na busca de um 'accuracy' melhor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regressão Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model = LogisticRegression(C=0.01, class_weight='balanced', max_iter=100, penalty='l1', solver='saga')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model.fit(X_train_df_treating_data, y_train_df_treating_data)\n",
    "\n",
    "y_pred_df_treating_data_logistic_reggresion = logistic_model.predict(X_val_df_treating_data)\n",
    "\n",
    "print(classification_report(y_val_df_treating_data, y_pred_df_treating_data_logistic_reggresion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model.fit(X_train_df_no_duration_outliers, y_train_df_no_duration_outliers)\n",
    "\n",
    "y_pred_df_no_duration_outliers_logistic_reggresion = logistic_model.predict(X_val_df_no_duration_outliers)\n",
    "\n",
    "print(classification_report(y_val_df_no_duration_outliers, y_pred_df_no_duration_outliers_logistic_reggresion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model.fit(X_train_df_duration_log, y_train_df_duration_log)\n",
    "\n",
    "y_pred_df_duration_log_logistic_reggresion = logistic_model.predict(X_val_df_duration_log)\n",
    "\n",
    "print(classification_report(y_val_df_duration_log, y_pred_df_duration_log_logistic_reggresion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model.fit(X_train_df_treating_data_scaled, y_train_df_treating_data)\n",
    "\n",
    "y_pred_df_treating_data_scaled_logistic_reggresion = logistic_model.predict(X_val_df_treating_data_scaled)\n",
    "\n",
    "print(classification_report(y_val_df_treating_data, y_pred_df_treating_data_scaled_logistic_reggresion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para garantir que os resultados não são overfitting. Vamos testar no 'test' agora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model.fit(X_train_df_treating_data_scaled, y_train_df_treating_data)\n",
    "\n",
    "y_pred_df_treating_data_scaled_logistic_reggresion_test = logistic_model.predict(X_test_df_treating_data_scaled)\n",
    "\n",
    "print(classification_report(y_test_df_treating_data, y_pred_df_treating_data_scaled_logistic_reggresion_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os resultados não são tão bons quanto RandomForest mas também são resultados bons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model = BernoulliNB(alpha=0.1, binarize=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model.fit(X_train_df_treating_data, y_train_df_treating_data)\n",
    "\n",
    "y_pred_df_treating_data_naive_bayes = nb_model.predict(X_val_df_treating_data)\n",
    "\n",
    "\n",
    "print(classification_report(y_val_df_treating_data, y_pred_df_treating_data_naive_bayes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model.fit(X_test_df_no_duration_outliers, y_test_df_no_duration_outliers)\n",
    "\n",
    "y_pred_df_no_duration_outliers_naive_bayes = nb_model.predict(X_val_df_no_duration_outliers)\n",
    "\n",
    "print(classification_report(y_val_df_no_duration_outliers, y_pred_df_no_duration_outliers_naive_bayes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model.fit(X_train_df_duration_log, y_train_df_duration_log)\n",
    "\n",
    "y_pred_df_duration_log_naive_bayes = nb_model.predict(X_val_df_duration_log)\n",
    "\n",
    "print(classification_report(y_val_df_duration_log, y_pred_df_duration_log_naive_bayes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model.fit(X_train_df_treating_data_scaled, y_train_df_treating_data)\n",
    "\n",
    "y_pred_df_treating_data_scaled_naive_bayes = nb_model.predict(X_val_df_treating_data_scaled)\n",
    "\n",
    "print(classification_report(y_val_df_treating_data, y_pred_df_treating_data_scaled_naive_bayes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para garantir que os resultados não são overfitting. Vamos testar no 'test' agora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model.fit(X_train_df_treating_data, y_train_df_treating_data)\n",
    "\n",
    "y_pred_df_treating_data_naive_bayes_test = nb_model.predict(X_test_df_treating_data)\n",
    "\n",
    "print(classification_report(y_test_df_treating_data, y_pred_df_treating_data_naive_bayes_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os resultados não são tão bons quanto RandomForest mas também são resultados bons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Árvore de Decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model = DecisionTreeClassifier(criterion='gini', max_depth=10, max_features=None, min_samples_leaf=10, min_samples_split=10, splitter='random')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model.fit(X_train_df_treating_data, y_train_df_treating_data)\n",
    "\n",
    "y_pred_df_treating_data_decision_tree = dt_model.predict(X_val_df_treating_data)\n",
    "\n",
    "print(classification_report(y_val_df_treating_data, y_pred_df_treating_data_decision_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model.fit(X_train_df_no_duration_outliers, y_train_df_no_duration_outliers)\n",
    "\n",
    "y_pred_df_no_duration_outliers_decision_tree = dt_model.predict(X_val_df_no_duration_outliers)\n",
    "\n",
    "print(classification_report(y_val_df_no_duration_outliers, y_pred_df_no_duration_outliers_decision_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model.fit(X_train_df_duration_log, y_train_df_duration_log)\n",
    "\n",
    "y_pred_df_duration_log_decision_tree = dt_model.predict(X_val_df_duration_log)\n",
    "\n",
    "print(classification_report(y_val_df_duration_log, y_pred_df_duration_log_decision_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model.fit(X_train_df_treating_data_scaled, y_train_df_treating_data)\n",
    "\n",
    "y_pred_df_treating_data_scaled_decision_tree = dt_model.predict(X_val_df_treating_data_scaled)\n",
    "\n",
    "print(classification_report(y_val_df_treating_data, y_pred_df_treating_data_scaled_decision_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que os resultados são bem iguais entre todos os testes. Vamos continuar com o resultado gerado pela base de dados 'df_treating_data_scaled' porque é o melhor entre todos. Para garantir que os resultados não são overfitting. Vamos testar no 'test' agora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model.fit(X_train_df_treating_data_scaled, y_train_df_treating_data)\n",
    "\n",
    "y_pred_df_treating_data_scaled_decision_tree_test = dt_model.predict(X_test_df_treating_data_scaled)\n",
    "\n",
    "print(classification_report(y_test_df_treating_data, y_pred_df_treating_data_scaled_decision_tree_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver, os resultados são bons e não estão em overfitting. Agora vamos seguir com os próximos testes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(algorithm='auto', n_neighbors=11, p=1, weights='distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(X_train_df_treating_data_scaled, y_train_df_treating_data)\n",
    "\n",
    "y_pred_df_treating_data_scaled_knn = knn.predict(X_val_df_treating_data_scaled)\n",
    "\n",
    "print(classification_report(y_val_df_treating_data, y_pred_df_treating_data_scaled_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_df_treating_data_scaled_knn_test = knn.predict(X_test_df_treating_data_scaled)\n",
    "\n",
    "print(classification_report(y_test_df_treating_data, y_pred_df_treating_data_scaled_knn_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os resultados acima são excelentes e mostram não possuir overfitting. KNN se mostra um dos melhores algoritmos em nossos testes por enquanto.\n",
    "\n",
    "Vamos continuar nossos testes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier(eval_metric='mlogloss', tree_method='hist', device='cuda')\n",
    "\n",
    "best_params = {\n",
    "    'subsample': 1.0,\n",
    "    'reg_lambda': 1,\n",
    "    'reg_alpha': 0.1,\n",
    "    'n_estimators': 200,\n",
    "    'max_depth': 9,\n",
    "    'learning_rate': 0.2,\n",
    "    'gamma': 0.2,\n",
    "    'colsample_bytree': 0.6\n",
    "}\n",
    "\n",
    "xgb_model.set_params(**best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model.fit(X_train_df_treating_data, y_train_df_treating_data)\n",
    "\n",
    "y_pred_df_treating_data_xg_boost = xgb_model.predict(X_val_df_treating_data)\n",
    "\n",
    "print(classification_report(y_val_df_treating_data, y_pred_df_treating_data_xg_boost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model.fit(X_train_df_no_duration_outliers, y_train_df_no_duration_outliers)\n",
    "\n",
    "y_pred_df_no_duration_outliers_xg_boost = xgb_model.predict(X_val_df_no_duration_outliers)\n",
    "\n",
    "print(classification_report(y_val_df_no_duration_outliers, y_pred_df_no_duration_outliers_xg_boost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model.fit(X_train_df_duration_log, y_train_df_duration_log)\n",
    "\n",
    "y_pred_df_duration_log_xg_boost = xgb_model.predict(X_val_df_duration_log)\n",
    "\n",
    "print(classification_report(y_val_df_duration_log, y_pred_df_duration_log_xg_boost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model.fit(X_train_df_treating_data_scaled, y_train_df_treating_data)\n",
    "\n",
    "y_pred_df_treating_data_scaled_xg_boost = xgb_model.predict(X_val_df_treating_data_scaled)\n",
    "\n",
    "print(classification_report(y_val_df_treating_data, y_pred_df_treating_data_scaled_xg_boost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver, nesse teste, a base de dados 'df_treating_data' e 'df_treating_data_scaled' emparatam. Na tentativa de desempatar e garantir que não existe um overfitting. Vamos rodar o teste nas duas bases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model.fit(X_train_df_treating_data, y_train_df_treating_data)\n",
    "\n",
    "y_pred_df_treating_data_xg_boost_test = xgb_model.predict(X_test_df_treating_data)\n",
    "\n",
    "print(classification_report(y_test_df_treating_data, y_pred_df_treating_data_xg_boost_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model.fit(X_train_df_treating_data_scaled, y_train_df_treating_data)\n",
    "\n",
    "y_pred_df_treating_data_scaled_xg_boost_test = xgb_model.predict(X_test_df_treating_data_scaled)\n",
    "\n",
    "print(classification_report(y_test_df_treating_data, y_pred_df_treating_data_scaled_xg_boost_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver, a accurary no 'df_treating_data' ganha por 1. Vamos fazer mais alguns testes para encontrar o melhor modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_model = lgb.LGBMClassifier(colsample_bytree=0.8388271726494101, learning_rate=0.20226242344096437, max_depth=12, min_child_weight=0.07965014662270789, min_split_gain=0.041166121435752816, n_estimators=401, num_leaves=112, reg_alpha=0.48655517463505216, reg_lambda=0.3009676977704801, subsample=0.9238490659063205)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_model.fit(X_train_df_treating_data, y_train_df_treating_data)\n",
    "\n",
    "y_pred_df_treating_data_light_gbm = lgb_model.predict(X_val_df_treating_data)\n",
    "\n",
    "print(classification_report(y_val_df_treating_data, y_pred_df_treating_data_light_gbm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_model.fit(X_train_df_no_duration_outliers, y_train_df_no_duration_outliers)\n",
    "\n",
    "y_pred_df_no_duration_outliers_light_gbm = lgb_model.predict(X_val_df_no_duration_outliers)\n",
    "\n",
    "print(classification_report(y_val_df_no_duration_outliers, y_pred_df_no_duration_outliers_light_gbm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_model.fit(X_train_df_duration_log, y_train_df_duration_log)\n",
    "\n",
    "y_pred_df_duration_log_light_gbm = lgb_model.predict(X_val_df_duration_log)\n",
    "\n",
    "print(classification_report(y_val_df_duration_log, y_pred_df_duration_log_light_gbm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_model.fit(X_train_df_treating_data_scaled, y_train_df_treating_data)\n",
    "\n",
    "y_pred_df_treating_data_scaled_light_gbm = lgb_model.predict(X_val_df_treating_data_scaled)\n",
    "\n",
    "print(classification_report(y_val_df_treating_data, y_pred_df_treating_data_scaled_light_gbm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui, podemos ver que o 'df_duration_log' apresenta aparentemente o melhor desempenho. Vamos rodar o teste para garantir que não existe overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_model.fit(X_train_df_duration_log, y_train_df_duration_log)\n",
    "\n",
    "y_pred_df_duration_log_light_gbm_test = lgb_model.predict(X_test_df_duration_log)\n",
    "\n",
    "print(classification_report(y_test_df_duration_log, y_pred_df_duration_log_light_gbm_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver, os resultados também são muito bons.\n",
    "\n",
    "Com base nos resultados apresentados, podemos identificar os três melhores algoritmos:\n",
    "\n",
    "1. Random Forest (melhor desempenho geral)\n",
    "2. LightGBM\n",
    "3. XGBoost\n",
    "\n",
    "Agora, com base nesses resultados, vamos realizar o Finetuning de Hiperparâmetros para o Random Forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning de Hiperparâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O finetuning de hiperparâmetros é um processo crucial na otimização de modelos de machine learning. Consiste em ajustar os parâmetros que não são aprendidos diretamente dos dados, mas que influenciam significativamente o desempenho do modelo.\n",
    "\n",
    "Importância:\n",
    "\n",
    "1. Melhora o desempenho do modelo\n",
    "2. Reduz o overfitting ou underfitting\n",
    "3. Adapta o modelo às características específicas do problema\n",
    "\n",
    "Métodos de Busca:\n",
    "\n",
    "- RandomizedSearchCV:\n",
    "\n",
    "1. Realiza uma busca aleatória no espaço de parâmetros\n",
    "2. Testa um número predefinido de combinações aleatórias\n",
    "3. Vantagens: Mais eficiente computacionalmente, especialmente para espaços de busca grandes\n",
    "4. Desvantagens: Pode não encontrar a combinação ótima absoluta, mas frequentemente encontra uma solução muito boa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "    'min_samples_split': [2, 5, 10, 15, 20],\n",
    "    'min_samples_leaf': [1, 2, 4, 6, 8],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "}\n",
    "\n",
    "\n",
    "n_iter_search = 100  \n",
    "random_search = RandomizedSearchCV(estimator=rf_classifier, param_distributions=param_grid, n_iter=n_iter_search, cv=5, scoring=make_scorer(accuracy_score), n_jobs=-1, random_state=42, verbose=2)\n",
    "\n",
    "random_search.fit(X_train_df_treating_data_scaled, y_train_df_treating_data)\n",
    "\n",
    "print(\"Melhores parâmetros (RandomizedSearchCV):\", random_search.best_params_)\n",
    "print(\"Melhor score (RandomizedSearchCV):\", random_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver acima, os melhores parâmetros são esses: {'n_estimators': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2', 'max_depth': None}\n",
    "\n",
    "Agora, vamos ajustar nosso Random Forest para ter todos esses parâmetros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com os melhores parâmetros em mãos, vamos realizar o teste novamente e ver como são os resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier = RandomForestClassifier(random_state=42, n_estimators=500, min_samples_split=2, min_samples_leaf=1,max_features='log2',max_depth=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier.fit(X_train_df_treating_data_scaled, y_train_df_treating_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df_treating_data_scaled_random_forest_2 = rf_classifier.predict(X_val_df_treating_data_scaled)\n",
    "\n",
    "print(classification_report(y_val_df_treating_data, y_df_treating_data_scaled_random_forest_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df_treating_data_scaled_random_forest_2_test = rf_classifier.predict(X_test_df_treating_data_scaled)\n",
    "\n",
    "print(classification_report(y_test_df_treating_data, y_df_treating_data_scaled_random_forest_2_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, com o nosso melhor modelo, vamos fazer o .predict para nosso df_test, salvar o resultado em CSV e enviar para a competição. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_treated = df_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_treated = df_test.drop(columns=['track_id', 'track_unique_id', 'artists', 'album_name', 'track_name'])\n",
    "df_test_treated['explicit'] = df_test_treated['explicit'].astype(int)\n",
    "encoding_dict = joblib.load('category_encoding.joblib')\n",
    "df_test_treated['track_genre_encoded'] = target_encode_test(df_test, 'track_genre', encoding_dict)\n",
    "df_test_treated = df_test_treated.drop(columns=['track_genre'])\n",
    "df_test_treated_scaled = scaler.transform(df_test_treated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predict_scaled = rf_classifier.predict(df_test_treated_scaled)\n",
    "final_result = pd.DataFrame({ 'track_unique_id': df_test['track_unique_id'], 'popularity_target': final_predict_scaled })\n",
    "final_result.to_csv('predictions_scaled.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testando um Ensemble Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble Model é uma técnica de aprendizado de máquina que combina múltiplos modelos base para melhorar o desempenho e a precisão das previsões em relação a um único modelo. A ideia por trás do ensemble é que, ao combinar diferentes modelos, os erros de um modelo podem ser compensados pelos acertos de outros, resultando em uma performance geral melhor.\n",
    "\n",
    "Tipos Comuns de Ensemble Models:\n",
    "\n",
    "1. Bagging (Bootstrap Aggregating)\n",
    "\n",
    "O objetivo do bagging é reduzir a variância de um modelo. Para isso, são criados vários subconjuntos aleatórios de dados de treino (com substituição) e, para cada subconjunto, um modelo é treinado. Em seguida, as previsões dos modelos são combinadas (geralmente por votação ou média).\n",
    "\n",
    "2. Boosting\n",
    "\n",
    "No boosting, os modelos são treinados de forma sequencial, onde cada modelo tenta corrigir os erros do anterior. Assim, os modelos seguintes dão mais importância aos exemplos mal classificados pelos anteriores.\n",
    "\n",
    "3. Stacking\n",
    "\n",
    "No stacking, diferentes tipos de modelos (não necessariamente do mesmo tipo) são treinados. Em vez de simplesmente combinar suas previsões, um outro modelo (chamado de meta-modelo) é treinado para aprender a melhor forma de combinar as previsões desses modelos base."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiro, vamos encontrar os melhores hiperparâmetros de cada modelo que vamos usar no Ensemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier(eval_metric='mlogloss', tree_method='hist', device='cuda')\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': randint(100, 1000),\n",
    "    'max_depth': randint(3, 15),\n",
    "    'learning_rate': uniform(0.01, 0.3),\n",
    "    'subsample': uniform(0.6, 0.4),\n",
    "    'colsample_bytree': uniform(0.6, 0.4),\n",
    "    'gamma': uniform(0, 0.5),\n",
    "    'reg_alpha': uniform(0, 1),\n",
    "    'reg_lambda': uniform(0, 1),\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(estimator=xgb_model, param_distributions=param_grid, n_iter=100, cv=5, verbose=2, random_state=42, n_jobs=-1, scoring=make_scorer(accuracy_score))\n",
    "\n",
    "random_search.fit(X_train_df_treating_data_scaled, y_train_df_treating_data)\n",
    "\n",
    "best_params_xgb_model = random_search.best_params_\n",
    "print(\"Best parameters found:\", best_params_xgb_model)\n",
    "print(\"Melhor score (RandomizedSearchCV):\", random_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output do código acima:\n",
    "\n",
    "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
    "Best parameters found: {'colsample_bytree': np.float64(0.8769744131561081), 'gamma': np.float64(0.13470616689926074), 'learning_rate': np.float64(0.08323765667433225), 'max_depth': 13, 'n_estimators': 473, 'reg_alpha': np.float64(0.21876421957307024), 'reg_lambda': np.float64(0.5581020020173412), 'subsample': np.float64(0.7615344684232164)}\n",
    "\n",
    "Melhor score (RandomizedSearchCV): 0.8152882205513784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_model = lgb.LGBMClassifier()\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': randint(100, 1000),\n",
    "    'max_depth': randint(3, 15),\n",
    "    'num_leaves': randint(20, 200),\n",
    "    'learning_rate': uniform(0.01, 0.3),\n",
    "    'colsample_bytree': uniform(0.6, 0.4),\n",
    "    'subsample': uniform(0.6, 0.4),\n",
    "    'min_child_weight': uniform(0.01, 0.1),\n",
    "    'min_split_gain': uniform(0, 0.1),\n",
    "    'reg_alpha': uniform(0, 1),\n",
    "    'reg_lambda': uniform(0, 1),\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=lgb_model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=100,\n",
    "    cv=5,\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    scoring=make_scorer(accuracy_score)\n",
    ")\n",
    "\n",
    "random_search.fit(X_train_df_treating_data_scaled, y_train_df_treating_data)\n",
    "\n",
    "best_params_lgb_model = random_search.best_params_\n",
    "print(\"Best parameters found:\", best_params_lgb_model)\n",
    "print(\"Best score (RandomizedSearchCV):\", random_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output do código acima:\n",
    "\n",
    "Best parameters found: {'colsample_bytree': np.float64(0.6943939678995823), 'learning_rate': np.float64(0.08682049682839718), 'max_depth': 13, 'min_child_weight': np.float64(0.06227328293819941), 'min_split_gain': np.float64(0.042754101835854964), 'n_estimators': 653, 'num_leaves': 143, 'reg_alpha': np.float64(0.10789142699330445), 'reg_lambda': np.float64(0.03142918568673425), 'subsample': np.float64(0.8545641645055122)}\n",
    "\n",
    "Best score (RandomizedSearchCV): 0.811904761904762"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model = LogisticRegression(class_weight='balanced', random_state=42)\n",
    "\n",
    "param_distributions = {\n",
    "    'C': loguniform(1e-3, 1e3),\n",
    "    'penalty': ['l1', 'l2', 'elasticnet'],\n",
    "    'solver': ['saga'],\n",
    "    'max_iter': [100, 500, 1000, 1500],\n",
    "    'l1_ratio': uniform(0, 1)\n",
    "}\n",
    "\n",
    "scoring = { 'accuracy': make_scorer(accuracy_score), 'precision': make_scorer(precision_score, average='weighted'), 'recall': make_scorer(recall_score, average='weighted'), 'f1': make_scorer(f1_score, average='weighted')}\n",
    "\n",
    "random_search = RandomizedSearchCV( estimator=logistic_model, param_distributions=param_distributions, n_iter=100, scoring=scoring, refit='f1', cv=5, verbose=2, n_jobs=-1,\n",
    "random_state=42 )\n",
    "\n",
    "random_search.fit(X_train_df_treating_data_scaled, y_train_df_treating_data)\n",
    "\n",
    "print(\"Best parameters found:\", random_search.best_params_)\n",
    "print(\"Best F1 score:\", random_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output do código acima:\n",
    "\n",
    "Best parameters found: {'C': np.float64(93.84800715909533), 'l1_ratio': np.float64(0.3567533266935893), 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga'}\n",
    "\n",
    "Best F1 score: 0.7550209677454942"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "\n",
    "param_distributions = {\n",
    "    'n_neighbors': randint(1, 30),\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "    'p': [1, 2],\n",
    "    'leaf_size': randint(10, 50),\n",
    "    'metric': ['minkowski', 'euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score, average='weighted'),\n",
    "    'recall': make_scorer(recall_score, average='weighted'),\n",
    "    'f1': make_scorer(f1_score, average='weighted')\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=knn,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=100,\n",
    "    scoring=scoring,\n",
    "    refit='f1',\n",
    "    cv=5,\n",
    "    verbose=2,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "random_search.fit(X_train_df_treating_data_scaled, y_train_df_treating_data)\n",
    "\n",
    "print(\"Best parameters found:\", random_search.best_params_)\n",
    "print(\"Best F1 score:\", random_search.best_score_)\n",
    "\n",
    "results = random_search.cv_results_\n",
    "for metric in scoring.keys():\n",
    "    print(f\"Best {metric} score: {results[f'mean_test_{metric}'][random_search.best_index_]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output do código acima:\n",
    "\n",
    "Best parameters found: {'algorithm': 'auto', 'leaf_size': 24, 'metric': 'manhattan', 'n_neighbors': 26, 'p': 2, 'weights': 'distance'}\n",
    "\n",
    "Best F1 score: 0.7838104588532426\n",
    "\n",
    "Best accuracy score: 0.7839\n",
    "\n",
    "Best precision score: 0.7840\n",
    "\n",
    "Best recall score: 0.7839\n",
    "\n",
    "Best f1 score: 0.7838\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "param_distributions = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'splitter': ['best', 'random'],\n",
    "    'max_depth': randint(3, 20),\n",
    "    'min_samples_split': randint(2, 20),\n",
    "    'min_samples_leaf': randint(1, 20),\n",
    "    'max_features': [None, 'sqrt', 'log2'] + list(uniform(0.1, 0.9).rvs(10)),\n",
    "    'class_weight': [None, 'balanced'],\n",
    "    'ccp_alpha': uniform(0, 0.05)\n",
    "}\n",
    "\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score, average='weighted'),\n",
    "    'recall': make_scorer(recall_score, average='weighted'),\n",
    "    'f1': make_scorer(f1_score, average='weighted')\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=dt_model,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=100,\n",
    "    scoring=scoring,\n",
    "    refit='f1',\n",
    "    cv=5,\n",
    "    verbose=2,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "random_search.fit(X_train_df_treating_data_scaled, y_train_df_treating_data)\n",
    "\n",
    "print(\"Best parameters found:\", random_search.best_params_)\n",
    "print(\"Best F1 score:\", random_search.best_score_)\n",
    "\n",
    "results = random_search.cv_results_\n",
    "for metric in scoring.keys():\n",
    "    print(f\"Best {metric} score: {results[f'mean_test_{metric}'][random_search.best_index_]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output do código acima:\n",
    "\n",
    "Best parameters found: {'ccp_alpha': np.float64(0.015239062907901453), 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 11, 'max_features': np.float64(0.6087974157673947), 'min_samples_leaf': 1, 'min_samples_split': 11, 'splitter': 'random'}\n",
    "\n",
    "Best F1 score: 0.7465959855465126\n",
    "\n",
    "Best accuracy score: 0.7472\n",
    "\n",
    "Best precision score: 0.7512\n",
    "\n",
    "Best recall score: 0.7472\n",
    "\n",
    "Best f1 score: 0.7466"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier(colsample_bytree=0.8769744131561081,gamma=0.13470616689926074,learning_rate=0.08323765667433225,max_depth=13,n_estimators=473,reg_alpha=0.21876421957307024,reg_lambda=0.5581020020173412,subsample=0.7615344684232164,use_label_encoder=False,eval_metric='mlogloss')\n",
    "\n",
    "lgb_model = lgb.LGBMClassifier(colsample_bytree=0.6943939678995823,learning_rate=0.08682049682839718,max_depth=13,min_child_weight=0.06227328293819941,min_split_gain=0.042754101835854964,n_estimators=653,num_leaves=143,reg_alpha=0.10789142699330445,reg_lambda=0.03142918568673425,subsample=0.8545641645055122)\n",
    "\n",
    "logistic_model = LogisticRegression(C=93.84800715909533,l1_ratio=0.3567533266935893,max_iter=1500,penalty='l1',solver='saga')\n",
    "\n",
    "knn_model = KNeighborsClassifier(algorithm='auto',leaf_size=24,metric='manhattan',n_neighbors=26,p=2,weights='distance')\n",
    "\n",
    "dt_model = DecisionTreeClassifier(ccp_alpha=0.015239062907901453,class_weight='balanced',criterion='entropy',max_depth=11,max_features=0.6087974157673947,min_samples_leaf=1, min_samples_split=11,splitter='random')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, vamos criar nosso Ensemble Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_model = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('rf_classifier', rf_classifier),\n",
    "        ('xgb_model', xgb_model),\n",
    "        ('lgb_model', lgb_model),\n",
    "        ('logistic_model', logistic_model),\n",
    "        ('knn_model', knn_model),\n",
    "        ('dt_model', dt_model)\n",
    "    ],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "ensemble_model.fit(X_train_df_treating_data_scaled, y_train_df_treating_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores = cross_val_score(ensemble_model, X_train_df_treating_data_scaled, y_train_df_treating_data, cv=5, scoring='accuracy')\n",
    "print(f\"Cross-validation accuracy: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = ensemble_model.predict(X_val_df_treating_data_scaled)\n",
    "\n",
    "print(classification_report(y_val_df_treating_data, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_essemple = ensemble_model.predict(df_test_treated_scaled)\n",
    "final_result_ensemble = pd.DataFrame({ 'track_unique_id': df_test['track_unique_id'], 'popularity_target': predict_essemple })\n",
    "final_result_ensemble.to_csv('predictions_ensemble.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver, o resulta é um pouco melhor do que com o modelo sozinho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver acima, a última feature está tomando toda a importância dos nossos dados e por isso não conseguimos progredir para além de 82%. Acredito que por causa do target_encode que fizemos no começo do nosso trabalho. Por isso, como um teste, vamos testar uma última forma para prever os resultados e ver como funciona."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usando Target Encode em toda base de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "blablabla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_and_encode_dataset(df, target, n_splits=5):\n",
    "    encoded_df = df.copy()\n",
    "    encoding_dict = {}\n",
    "    scaler_dict = {}\n",
    "\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    \n",
    "    for column in df.columns:\n",
    "        if column == target:\n",
    "            continue\n",
    "        \n",
    "        encoded = np.zeros(len(df))\n",
    "        column_dict = {}\n",
    "        \n",
    "        # Target encoding\n",
    "        for train_idx, val_idx in kf.split(df):\n",
    "            target_means = df.iloc[train_idx].groupby(column)[target].mean()\n",
    "            encoded[val_idx] = df[column].iloc[val_idx].map(target_means)\n",
    "            \n",
    "            column_dict.update(target_means.to_dict())\n",
    "        \n",
    "        global_mean = df[target].mean()\n",
    "        encoded = np.where(np.isnan(encoded), global_mean, encoded)\n",
    "        \n",
    "        column_dict['_global_mean'] = global_mean\n",
    "        encoding_dict[column] = column_dict\n",
    "        \n",
    "        # Normalization\n",
    "        scaler = StandardScaler()\n",
    "        normalized = scaler.fit_transform(encoded.reshape(-1, 1)).flatten()\n",
    "        \n",
    "        encoded_df[f\"{column}_encoded_normalized\"] = normalized\n",
    "        scaler_dict[column] = scaler\n",
    "    \n",
    "    return encoded_df, encoding_dict, scaler_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_normalize_and_encode(df, encoding_dict, scaler_dict):\n",
    "    encoded_df = df.copy()\n",
    "    \n",
    "    for column, column_dict in encoding_dict.items():\n",
    "        if column in df.columns:\n",
    "            global_mean = column_dict['_global_mean']\n",
    "            \n",
    "            # Apply target encoding\n",
    "            encoded = df[column].map(column_dict)\n",
    "            encoded = encoded.fillna(global_mean)\n",
    "            \n",
    "            # Apply normalization\n",
    "            scaler = scaler_dict[column]\n",
    "            normalized = scaler.transform(encoded.values.reshape(-1, 1)).flatten()\n",
    "            \n",
    "            encoded_df[f\"{column}_encoded_normalized\"] = normalized\n",
    "        else:\n",
    "            print(f\"Warning: Column '{column}' not found in the input DataFrame.\")\n",
    "    \n",
    "    return encoded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df.copy()\n",
    "new_df = new_df.drop(columns=['track_unique_id', 'track_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_df, encoding_dict, scaler_dict = normalize_and_encode_dataset(new_df, 'popularity_target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_df = encoded_df.drop(columns=['artists', 'album_name', 'track_name', 'duration_ms', 'explicit', 'danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'time_signature', 'track_genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = encoded_df.drop('popularity_target', axis=1)\n",
    "y = encoded_df['popularity_target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_temp_df_no_genres, X_test_df_no_genres, y_temp_df_no_genres, y_test_df_no_genres = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_df_no_genres, X_val_df_no_genres, y_train_df_no_genres, y_val_df_no_genres = train_test_split(X_temp_df_no_genres, y_temp_df_no_genres, test_size=0.25, random_state=42)\n",
    "\n",
    "print(f\"Tamanho do conjunto de treino: {len(X_train_df_no_genres)}\")\n",
    "print(f\"Tamanho do conjunto de validação: {len(X_val_df_no_genres)}\")\n",
    "print(f\"Tamanho do conjunto de teste: {len(X_test_df_no_genres)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.90      0.91      8178\n",
      "           1       0.90      0.92      0.91      7782\n",
      "\n",
      "    accuracy                           0.91     15960\n",
      "   macro avg       0.91      0.91      0.91     15960\n",
      "weighted avg       0.91      0.91      0.91     15960\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_classifier.fit(X_train_df_no_genres, y_train_df_no_genres)\n",
    "\n",
    "y_pred_df_no_genres = rf_classifier.predict(X_val_df_no_genres)\n",
    "\n",
    "print(classification_report(y_val_df_no_genres, y_pred_df_no_genres))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_df_no_genres = rf_classifier.predict(X_test_df_no_genres)\n",
    "\n",
    "print(classification_report(y_test_df_no_genres, y_pred_df_no_genres))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model.fit(X_train_df_no_genres, y_train_df_no_genres)\n",
    "\n",
    "y_pred_df_no_genres = xgb_model.predict(X_val_df_no_genres)\n",
    "\n",
    "print(classification_report(y_val_df_no_genres, y_pred_df_no_genres))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_df_no_genres = xgb_model.predict(X_test_df_no_genres)\n",
    "\n",
    "print(classification_report(y_test_df_no_genres, y_pred_df_no_genres))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_model.fit(X_train_df_no_genres, y_train_df_no_genres)\n",
    "\n",
    "y_pred_df_no_genres = lgb_model.predict(X_val_df_no_genres)\n",
    "\n",
    "print(classification_report(y_val_df_no_genres, y_pred_df_no_genres))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_df_no_genres = lgb_model.predict(X_test_df_no_genres)\n",
    "\n",
    "print(classification_report(y_test_df_no_genres, y_pred_df_no_genres))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Inteli\\Mod03\\PonderadaSemana04\\proximo-hit-spotify\\Ponderada\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "135 fits failed out of a total of 500.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "115 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Inteli\\Mod03\\PonderadaSemana04\\proximo-hit-spotify\\Ponderada\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Inteli\\Mod03\\PonderadaSemana04\\proximo-hit-spotify\\Ponderada\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Inteli\\Mod03\\PonderadaSemana04\\proximo-hit-spotify\\Ponderada\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Inteli\\Mod03\\PonderadaSemana04\\proximo-hit-spotify\\Ponderada\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Inteli\\Mod03\\PonderadaSemana04\\proximo-hit-spotify\\Ponderada\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Inteli\\Mod03\\PonderadaSemana04\\proximo-hit-spotify\\Ponderada\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Inteli\\Mod03\\PonderadaSemana04\\proximo-hit-spotify\\Ponderada\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Inteli\\Mod03\\PonderadaSemana04\\proximo-hit-spotify\\Ponderada\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Inteli\\Mod03\\PonderadaSemana04\\proximo-hit-spotify\\Ponderada\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1103: UserWarning: One or more of the test scores are non-finite: [0.90367586        nan 0.90279866 0.9036132  0.90492899 0.90413534\n",
      "        nan 0.90329992 0.90396825 0.90403091 0.90423977 0.90355054\n",
      "        nan 0.90494987 0.90407268        nan 0.90323726 0.90446951\n",
      " 0.90463659        nan 0.90407268 0.90348789 0.90403091 0.90430242\n",
      " 0.9037594         nan 0.90307018 0.90398914 0.90517962 0.9047619\n",
      " 0.90419799 0.90388471        nan 0.90453216        nan 0.90292398\n",
      " 0.9036132  0.90469925        nan 0.90388471 0.90553467        nan\n",
      " 0.90423977        nan 0.90382206 0.9040518  0.90442774 0.90530493\n",
      "        nan 0.90365497 0.90419799        nan        nan 0.90474102\n",
      "        nan        nan 0.90426065 0.90334169 0.90438596 0.9033208\n",
      " 0.90396825        nan        nan 0.90371763 0.90426065 0.90340434\n",
      " 0.90398914 0.90325815 0.90388471 0.90474102 0.90352966 0.90352966\n",
      " 0.90365497        nan        nan 0.90369674        nan        nan\n",
      " 0.9040518         nan 0.90365497 0.90440685 0.90371763 0.90388471\n",
      " 0.90415622 0.90388471        nan        nan 0.90426065 0.90382206\n",
      " 0.90494987        nan 0.90382206 0.9040518         nan 0.90438596\n",
      " 0.90340434 0.90413534 0.90411445 0.90407268]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores parâmetros (RandomizedSearchCV): {'n_estimators': 500, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': None}\n",
      "Melhor score (RandomizedSearchCV): 0.9055346700083543\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "    'min_samples_split': [2, 5, 10, 15, 20],\n",
    "    'min_samples_leaf': [1, 2, 4, 6, 8],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "}\n",
    "\n",
    "\n",
    "n_iter_search = 100  \n",
    "random_search = RandomizedSearchCV(estimator=rf_classifier, param_distributions=param_grid, n_iter=n_iter_search, cv=5, scoring=make_scorer(accuracy_score), n_jobs=-1, random_state=42, verbose=2)\n",
    "\n",
    "random_search.fit(X_train_df_no_genres, y_train_df_no_genres)\n",
    "\n",
    "print(\"Melhores parâmetros (RandomizedSearchCV):\", random_search.best_params_)\n",
    "print(\"Melhor score (RandomizedSearchCV):\", random_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Melhores parâmetros (RandomizedSearchCV): {'n_estimators': 500, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': None}\n",
    "Melhor score (RandomizedSearchCV): 0.9055346700083543"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_target_encoding = df_test.copy()\n",
    "df_test_target_encoding = df_test_target_encoding.drop(columns=['track_unique_id', 'track_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_target_encoding = apply_normalize_and_encode(df_test_target_encoding, encoding_dict, scaler_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_target_encoding = df_test_target_encoding.drop(columns=['artists', 'album_name', 'track_name', 'duration_ms', 'explicit', 'danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'time_signature', 'track_genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_target_encoding = rf_classifier.predict(df_test_target_encoding)\n",
    "result = pd.DataFrame({ 'track_unique_id': df_test['track_unique_id'], 'popularity_target': predict_target_encoding })\n",
    "result.to_csv('result.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Melhores parâmetros (RandomizedSearchCV): {'n_estimators': 500, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': None}\n",
    "Melhor score (RandomizedSearchCV): 0.9055346700083543"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
