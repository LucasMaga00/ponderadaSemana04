{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiro, vamos realizar a importação de todas as bibliotecas que usaremos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.model_selection import KFold, train_test_split, RandomizedSearchCV, GridSearchCV, cross_val_predict, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, make_scorer\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, StackingClassifier, GradientBoostingClassifier, ExtraTreesClassifier, BaggingClassifier, AdaBoostClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, Lasso, RidgeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import uniform, randint, loguniform\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import joblib\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, vamos importar nossos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('../test.csv')\n",
    "df = pd.read_csv('../train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None) # Configuracao para mostrar todas as colunas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entendendo o significado de todas as colunas\n",
    "\n",
    "É de extrema importância entender todas as colunas, por isso, vamos copiar e colar o significado delas:\n",
    "\n",
    "- track_id: O ID único de cada música\n",
    "    \n",
    "- artists: Nome dos(as) artistas que performaram a música, separados por ';'\n",
    "    \n",
    "- album_name: Nome do álbum no qual aparece a música\n",
    "    \n",
    "- track_name: Nome da música\n",
    "    \n",
    "- duration_ms: A duração da música em milissegundos\n",
    "    \n",
    "- explicit: Boolean indicando se a música possui conteúdo explícito\n",
    "    \n",
    "- danceability: Descreve quanto uma música é \"dançante\" (0.0 = menos dançante, 1.0 = mais dançante)\n",
    "    \n",
    "- energy: Representa a intensidade e atividade de uma música (0.0 = baixa energia, 1.0 = alta energia)\n",
    "    \n",
    "- key: A tonalidade musical da faixa mapeada usando a notação padrão de Classe de Altura (12 notas musicais)\n",
    "    \n",
    "- loudness: Nível geral de volume da faixa em decibéis (dB)\n",
    "    \n",
    "- mode: Indica a modalidade (maior ou menor) da faixa\n",
    "    \n",
    "- speechiness: Detecta a presença de palavras faladas na faixa\n",
    "    \n",
    "- acousticness: Medida de confiança sobre se a faixa é acústica (0,0 = não acústica, 1,0 = altamente acústica)\n",
    "    \n",
    "- instrumentalness: Prediz se uma faixa contém vocais (0,0 = contém vocais, 1,0 = instrumental)\n",
    "    \n",
    "- liveness: Detecta a presença de uma audiência na gravação (0,0 = gravação em estúdio, 1,0 = performance ao vivo)\n",
    "    \n",
    "- valence: Mede a positividade musical transmitida por uma faixa (0,0 = negativa, 1,0 = positiva)\n",
    "    \n",
    "- tempo: Tempo estimado da faixa em batidas por minuto (BPM)\n",
    "    \n",
    "- time_signature: Assinatura de tempo estimada da faixa (de 3 a 7)\n",
    "    \n",
    "- track_genre: O gênero da música\n",
    "    \n",
    "- popularity_target: Boolean indicando se a música é popular ou não\n",
    "\n",
    "Realizando a análise das colunas, fiquei em dúvida sobre a diferença entre a coluna 'tempo' e 'time_signature'. Por isso, realizei uma análise mais profunda no significado delas:\n",
    "\n",
    "* tempo (Batidas por minuto):\n",
    "   * O tempo representa a velocidade ou ritmo de uma faixa, medido em batidas por minuto (BPM).\n",
    "   * O tempo médio é de cerca de 122 BPM, o que representa um ritmo moderado e enérgico.\n",
    "   * O tempo mínimo é 0 BPM (o que pode indicar dados ausentes ou faixas muito lentas), e o máximo é cerca de 223 BPM (muito rápido).\n",
    "\n",
    "* time_signature (Fórmula de compasso):\n",
    "   * A fórmula de compasso representa a estrutura rítmica de uma faixa, indicando quantas batidas existem em cada compasso e qual valor de nota representa uma batida.\n",
    "   * Os valores geralmente variam de 3 a 7, sendo 4 o mais comum (representando o compasso 4/4, que é padrão em muitos gêneros).\n",
    "   * A partir das estatísticas, podemos ver que a mediana e os percentis 25 e 75 são 4, confirmando que o compasso 4/4 é realmente o mais comum.\n",
    "   * O mínimo de 0 pode indicar dados ausentes ou fórmulas de compasso não convencionais.\n",
    "\n",
    "   Primeiro dou uma olhada por cima dos dados apenas para entender quais colunas são númericas e categóricas. Também tenho a intenção de ver elas como dados reais e por isso chamo o comando `df.head(3)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora partindo para uma análise mais profunda das colunas numéricas, começo com uma análise da estatística descritiva de cada coluna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com o output acima, já é possível observar que valores iguais a 0 em 'tempo' e 'time_signature' provavelmente são missing values. Chegamos a essa conclusão porque músicas com 0 BPM não existem, mesmo muito lentas. E 'time_sigture' já comenta na definição das colunas que os valores vão de 3 a 7, ou seja, 0 é incorreto. Não realizamos a correção desses valores faltantes nesse exato momento, mas em breve voltaremos com eles.\n",
    "\n",
    "## Exploração e Visualização dos Dados\n",
    "\n",
    "Agora, na intenção de entender os dados e descobrir padrões, vamos realizar uma exploração e visualização dos dados! Para isso, vamos utilizar bibliotecas como Matplot e Seaborn. Nossa missão aqui é descobrir padrões, correlações e tendências nos dados. Vamos usar visualizações eficazes para comunicar os insights e justificar nossas futuras escolhas de features e modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo um estilo para nossos graficos e alterando o tamanho padrão das figuras geradas pelo Matplotlib\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para o começo da nossa análise, é importante saber a quantidade de músicas que são populares ou não e saber como está a distribuição entre elas. No gráfico gerado a seguir, é possível observar que existe uma divisão bem harmoniosa entre músicas populares e não populares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='popularity_target', data=df)\n",
    "plt.title('Distribution of Song Popularity')\n",
    "plt.xlabel('Popularity (0: Not Popular, 1: Popular)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partindo com nossa análise, vamos agora observar nossas variáveis numéricas e a relação entre elas. O Heatmap é um gráfico perfeito para isso que demonstra as relações entre as colunas. Resumindo bastante funciona da forma a seguir: \n",
    "\n",
    "Os valores de correlação variam de -1 a 1:\n",
    "\n",
    "- **+1**: Correlação positiva perfeita. À medida que uma variável aumenta, a outra também aumenta.\n",
    "- **-1**: Correlação negativa perfeita. À medida que uma variável aumenta, a outra diminui.\n",
    "- **0**: Nenhuma correlação. As duas variáveis não afetam uma à outra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = ['duration_ms', 'danceability', 'energy', 'key', 'loudness', 'speechiness', \n",
    "                      'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(df[numerical_features].corr(), annot=True, cmap='coolwarm', linewidths=0.5)\n",
    "plt.title('Correlation Heatmap of Numerical Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizando a análise do Heatmap acima, é possível identificar alguns padrões importantes sobre nossa base de dados.\n",
    "\n",
    "1. Correlação forte entre 'energy' e 'loudness': Existe uma correlação positiva forte (0.76) entre 'energy' e 'loudness', indicando que músicas mais enérgicas tendem a ser mais altas.\n",
    "\n",
    "2. Correlação negativa entre 'acousticness' e 'energy': Há uma forte correlação negativa (-0.73) entre 'acousticness' e 'energy', sugerindo que músicas mais acústicas tendem a ser menos enérgicas.\n",
    "\n",
    "3. Correlação negativa entre 'acousticness' e 'loudness': Similarmente, existe uma correlação negativa moderada (-0.59) entre 'acousticness' e 'loudness', indicando que músicas acústicas tendem a ser menos altas.\n",
    "\n",
    "4. Correlação positiva entre 'danceability' e 'valence': Há uma correlação positiva moderada (0.48) entre 'danceability' e 'valence', sugerindo que músicas mais dançantes tendem a ter um tom emocional mais positivo.\n",
    "\n",
    "5. Correlação negativa entre 'instrumentalness' e 'loudness': Observa-se uma correlação negativa moderada (-0.43) entre 'instrumentalness' e 'loudness', indicando que músicas mais instrumentais tendem a ser menos altas.\n",
    "\n",
    "6. Pouca correlação com 'duration_ms': A 'duration_ms' tem correlações fracas com a maioria das outras características, sugerindo que o comprimento da música não está fortemente relacionado com suas outras propriedades acústicas.\n",
    "\n",
    "7. Correlações fracas com 'key': A 'key' tem correlações muito fracas com outras características, indicando que não há uma relação forte entre a tonalidade e outros aspectos musicais neste conjunto de dados.\n",
    "\n",
    "8. Correlações moderadas com 'valence': A 'valence' tem correlações moderadas positivas com 'danceability' (0.48) e 'energy' (0.26), sugerindo que músicas mais positivas tendem a ser mais dançantes e enérgicas.\n",
    "\n",
    "9. Pouca correlação entre 'tempo' e outras características: O 'tempo' da música tem correlações relativamente fracas com outras características, com a mais forte sendo com 'energy' (0.24).\n",
    "\n",
    "10. Correlação fraca entre 'speechiness' e outras características: 'Speechiness' tem correlações geralmente fracas com outras características, com a mais notável sendo com 'liveness' (0.21).\n",
    "\n",
    "11. 'Liveness' tem correlações fracas: A característica 'liveness' não mostra correlações fortes com nenhuma outra característica, sugerindo que é relativamente independente das outras propriedades musicais.\n",
    "\n",
    "Saber desses padrão será importante para quando começarmos a selecionar as features para o treinamento do nosso modelo! Porque aqui é possível observar que alguns colunas estão extremamente ligadas com outras.\n",
    "\n",
    "Agora, queremos entender como diferentes características musicais se relacionam com a popularidade das músicas. Por isso, vamos criar alguns gráficos para realizar essa visualização.\n",
    "\n",
    "Com essa análise, vamos identificar quais características musicais têm maior influência na popularidade de uma música."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "features = ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', 'instrumentalness']\n",
    "for i, feature in enumerate(features):\n",
    "    sns.boxplot(x='popularity_target', y=feature, data=df, ax=axes[i//3][i%3])\n",
    "    axes[i//3][i%3].set_title(f'{feature.capitalize()} by Popularity')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observando o gráfico acima, conseguimos ter alguns insights.\n",
    "\n",
    "1. Danceability (Dançabilidade):\n",
    "\n",
    "Há uma ligeira tendência de músicas populares (1) terem maior dançabilidade.\n",
    "A diferença é pequena, mas notável, o que sugere que músicas mais dançantes têm uma probabilidade um pouco maior de serem populares.\n",
    "\n",
    "2.Instrumentalness (Instrumentalidade):\n",
    "\n",
    "Músicas populares tendem a ter menor instrumentalidade.\n",
    "Isso sugere que músicas com vocais são geralmente mais populares do que músicas puramente instrumentais.\n",
    "\n",
    "Agora, para entender quais gêneros proporcionam mais sucessos às músicas, vamos criar um gráfico para visualizar os 10 melhores gêneros em termos de músicas populares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_genres = df['track_genre'].value_counts().nlargest(10)\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=top_genres.index, y=top_genres.values)\n",
    "plt.title('Top 10 Genres by Count')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "sns.scatterplot(data=df, x='energy', y='danceability', hue='popularity_target', palette='viridis')\n",
    "plt.title('Energy vs. Danceability (Colored by Popularity)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Análisando o gráfico acima, podemos observar que a popularidade não parece ser exclusivamente determinada por altos níveis de energia e dançabilidade, já que músicas populares existem em diversos níveis de energia e dançabilidade, sugerindo que outros fatores também influenciam a popularidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(data=df, x='duration_ms', bins=50, kde=True)\n",
    "plt.title('Distribution of Song Durations')\n",
    "plt.xlabel('Duration (ms)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observando a duração das músicas, podemos observar que há uma concentração muito alta de músicas com duração menor. Também observamos que existem músicas com durações extremamente longas. Estes podem ser álbuns inteiros, performances ao vivo, ou erros nos dados.\n",
    "\n",
    "- A assimetria da distribuição pode afetar análises estatísticas, sendo necessário considerar transformações ou métodos robustos. Em breve voltaremos nesse tópico ao tratar os dados.\n",
    "\n",
    "Já o gráfico de barras empilhadas abaixo apresenta uma comparação visual da proporção de conteúdo explícito entre músicas populares e não populares "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explicit_by_popularity = df.groupby('popularity_target')['explicit'].value_counts(normalize=True).unstack()\n",
    "explicit_by_popularity.plot(kind='bar', stacked=True)\n",
    "plt.title('Proportion of Explicit Content by Popularity')\n",
    "plt.xlabel('Popularity')\n",
    "plt.ylabel('Proportion')\n",
    "plt.legend(title='Explicit', loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observando o gráfico acima, podemos observar que:\n",
    "\n",
    "1. A maioria das músicas, tanto populares quanto não populares, não contém conteúdo explícito.\n",
    "2. Há uma ligeira tendência de músicas populares terem uma proporção um pouco maior de conteúdo explícito em comparação com as não populares.\n",
    "3. A presença de conteúdo explícito não parece ser um fator determinante para a popularidade de uma música, dada a pequena diferença observada.\n",
    "\n",
    "Agora para fechar nossa análise, vamos comparar a distribuição da duração das músicas entre as categorias de popularidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxenplot(x='popularity_target', y='duration_ms', data=df)\n",
    "plt.title('Song Duration Distribution by Popularity')\n",
    "plt.xlabel('Popularity (0: Not Popular, 1: Popular)')\n",
    "plt.ylabel('Duration (ms)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observando o gráfico acima, vemos que:\n",
    "\n",
    "1. As medianas de duração para músicas populares e não populares são muito semelhantes, sugerindo que a duração por si só não é um forte indicador de popularidade.\n",
    "2. A dispersão (representada pelo tamanho das caixas) é ligeiramente menor para músicas populares, indicando uma maior consistência na duração dessas faixas.\n",
    "3. Existem muitos outliers em ambas as categorias, representando músicas com durações excepcionalmente longas.\n",
    "4. As músicas populares parecem ter menos outliers extremos em comparação com as não populares, especialmente na faixa de duração mais longa.\n",
    "5. A maioria das músicas, independentemente da popularidade, tem duração dentro de um intervalo relativamente estreito, como evidenciado pelo tamanho das caixas do boxplot.\n",
    "6. Há uma leve tendência de músicas populares terem durações um pouco mais curtas, observável pela posição ligeiramente inferior da caixa para músicas populares.\n",
    "\n",
    "Os insights mais importantes que encontramos em nossa análise incluem: a ligeira tendência de músicas populares terem maior energia e dançabilidade; a predominância de conteúdo não explícito em ambas as categorias de popularidade, com uma sutil inclinação para mais conteúdo explícito em músicas populares; e a observação de que a duração das músicas não é um forte indicador de popularidade, embora músicas populares tendam a ter durações mais consistentes. Além disso, notamos correlações significativas entre certas características musicais, como a relação positiva entre energia e volume (loudness), e negativa entre acústica e energia.\n",
    "\n",
    "Ainda é muito cedo para entrarmos na escolha das features para nosso modelo, mas já é possível observar que não existe uma coluna em específica que determina a popularidade das músicas, com isso, é bastante provável que vamos utilizar todas as colunas para treinar nosso modelo, excluindo apenas as colunas de identificação.\n",
    "\n",
    "## Formulação de Hipóteses\n",
    "\n",
    "#### Hipótese 01: Influência da dançabilidade na era do TikTok\n",
    "\n",
    "Com a popularização do TikTok, onde coreografias virais são frequentes, músicas mais dançantes podem ter maior probabilidade de se tornarem populares. Esta hipótese sugere uma correlação positiva entre a dançabilidade de uma música e sua popularidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(2, 2, 1)\n",
    "sns.boxplot(x='popularity_target', y='danceability', data=df)\n",
    "plt.title('Dançabilidade vs. Popularidade')\n",
    "plt.xlabel('Popularidade (0: Não Popular, 1: Popular)')\n",
    "plt.ylabel('Dançabilidade')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É possível observar que a média de músicas dançantes é um pouco mais alto para músicas populares, mas a diferença não é tão grande assim, logo, não indica extrema importância se a música é dançante ou não para ela ser popular.\n",
    "\n",
    "#### Hipótese 02: Conteúdo explícito em músicas de temática triste\n",
    "\n",
    "Músicas categorizadas como \"sad\" ou emocionalmente intensas podem ter uma maior tendência a conter conteúdo explícito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(2, 2, 2)\n",
    "sad_genres = ['sad', 'melancholic', 'emotional']  # Ajuste conforme necessário\n",
    "df['is_sad'] = df['track_genre'].isin(sad_genres)\n",
    "sns.barplot(x='is_sad', y='explicit', data=df)\n",
    "plt.title('Conteúdo Explícito em Músicas Tristes vs. Outras')\n",
    "plt.xlabel('Gênero Triste')\n",
    "plt.ylabel('Proporção de Conteúdo Explícito')\n",
    "df = df.drop(columns='is_sad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É possível observar que o conteúdo explícito está extremamente presente em músicas classificadas como 'sad', 'melancholic' ou 'emotional'. Comprovando nossa hipótese.\n",
    "\n",
    "#### Hipótese 03: Popularidade de músicas com temática melancólica\n",
    "\n",
    "Músicas classificadas como 'sad' estão entre as mais populares, principalmente porque hoje a depressão é o problema do século."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_genres = df['track_genre'].value_counts().nlargest(10)\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=top_genres.index, y=top_genres.values)\n",
    "plt.title('Top 10 Genres by Count')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É possível ver que o gênero 'sad' é o segundo gênero com maior sucesso de músicas populares. Comprovando nossa hipótese.\n",
    "\n",
    "#### Hipótese 04: Relação inversa entre instrumentalidade e popularidade\n",
    "\n",
    "Músicas com alto grau de instrumentalidade (pouco ou nenhum vocal) podem tender a ser menos populares, possivelmente devido à preferência do público mainstream por músicas com letras e vozes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(2, 2, 4)\n",
    "sns.boxplot(x='popularity_target', y='instrumentalness', data=df)\n",
    "plt.title('Instrumentalidade vs. Popularidade')\n",
    "plt.xlabel('Popularidade (0: Não Popular, 1: Popular)')\n",
    "plt.ylabel('Instrumentalidade')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É possível observar que existem músicas populares e que são instrumentais, mas, em maioria, elas são classificadas como não populares. Comprovando nossa hipótese.\n",
    "\n",
    "## Limpeza e Tratamento de Valores Nulos\n",
    "\n",
    "### Tratamento de valores duplicados\n",
    "\n",
    "Fazer a limpeza de valores duplicados é importantes pois valores duplicados podem prejudicar no aprendizado do nosso algoritmo. Para realizar a limpeza, vamos primeiro checar se existem valores duplicados e caso existirem, vamos excluir todos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicated_values = df[df.duplicated()]\n",
    "print(len(duplicated_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver acima, não existem valores duplicados. Assim, seguiremos com nossa análise\n",
    "\n",
    "### Tratamento de missing values\n",
    "\n",
    "Missing values são valores = null\n",
    "\n",
    "É importante verificar a existência deles e resolver os valores faltantes caso existam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver acima, também não existem valores faltantes.\n",
    "\n",
    "Agora, vamos verificar valores que são iguais a 0. Como identificamos lá no começo desse notebook, já sabemos de alguns valores que não deveriam estar iguais a 0. Também vamos procurar por novos valores iguais a 0 e que não deveriam estar assim, caso existam, vamos resolver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_count = (df == 0).sum()\n",
    "print(zero_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver acima, as colunas 'time_signature' e 'tempo' possuem valores iguais a 0 e elas não deveriam estar assim:\n",
    "\n",
    "1. Tempo:\n",
    "\n",
    "- Representa a velocidade da música em batidas por minuto (BPM).\n",
    "- Um valor 0 significaria que não há batidas, o que é musicalmente impossível.\n",
    "- Tempos típicos variam de cerca de 60 BPM (lento) a 200 BPM (muito rápido).\n",
    "\n",
    "\n",
    "2. Time signature (fórmula de compasso):\n",
    "\n",
    "- Indica quantas batidas há por compasso e qual nota representa uma batida.\n",
    "- É escrita como uma fração, por exemplo, 4/4 ou 3/4.\n",
    "- Um valor 0 não faria sentido, pois implicaria em nenhuma batida por compasso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['time_signature'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['tempo'].describe(), df['tempo'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para resolver esses 2 problemas, vamos: \n",
    "\n",
    "- Substituir os valores de 'time_signature' pela moda, que é 4\n",
    "- Substituir os valores de 'tempo' pela mediana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempo_median = df['tempo'].median()\n",
    "df_treating_data = df.copy()\n",
    "df_treating_data['tempo'] = df_treating_data['tempo'].replace(0,tempo_median)\n",
    "df_treating_data['time_signature'] = df_treating_data['time_signature'].replace(0,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identificação de outliers e correção\n",
    "\n",
    "As colunas que vamos visualizar e depois tratar os outliers são as colunas: 'duration_ms', 'loudness' e 'tempo'.\n",
    "\n",
    "Realizei a escolha dessas três colunas porque todas as outras colunas numéricas se constituem de valores que vâo de 0 a 1. Algumas até possuem outliers mas são features importantes e que quero manter para preservar a pureza dos dados em features que vão de 0 a 1. Mais tarde, vamos minimizar os impactos que esses outliers podem causar com o standardScaler\n",
    "\n",
    "Agora partindo para a identificação dos outliers que escolhemos, vamos começar visualizando em boxplot os possíveis outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=df_treating_data, y='duration_ms')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observando o gráfico acima, é possívei ver que 'duration_ms' possui vários outliers, vamos guardar essa informação e em breve corrigir eles.\n",
    "\n",
    "Agora fazendo a análise dos outliers de 'loudness', vamos desenhar outro boxplot para realizar essa visualização:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=df_treating_data, y='loudness')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora fazendo a análise dos outliers de 'tempo', vamos desenhar outro boxplot para realizar essa visualização:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=df_treating_data, y='tempo')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após uma análise cuidadosa dos dados, incluindo a presença de outliers em colunas como 'duration_ms', 'loudness' e 'tempo', decidimos manter o dataset em seu estado original, sem realizar nenhuma transformação ou exclusão neste momento.\n",
    "\n",
    "Esta decisão se baseia nas seguintes considerações:\n",
    "\n",
    "1. Preservação da integridade dos dados: Cada característica de uma música, mesmo aquelas que parecem estatisticamente atípicas, pode conter informações valiosas sobre a natureza única da faixa e potencialmente sobre sua popularidade.\n",
    "\n",
    "2. Flexibilidade para análises futuras: Manter todos os dados em seu estado original nos proporciona máxima flexibilidade para realizar diversos tipos de análises e experimentos posteriormente.\n",
    "\n",
    "3. Seleção de features posterior: Decidimos adiar a seleção de features para uma etapa posterior do processo. Isso nos permitirá tomar decisões mais informadas sobre quais características são mais relevantes para nosso modelo, baseando-nos em análises mais aprofundadas e experimentos iniciais.\n",
    "\n",
    "4. Captura de padrões complexos: No domínio musical, o que pode parecer um outlier ou uma característica irrelevante pode, na verdade, ser parte de um padrão mais complexo que contribui para a popularidade de uma faixa.\n",
    "\n",
    "5. Abordagem holística: Ao manter todos os dados, estamos adotando uma visão holística do problema, permitindo que nosso modelo potencialmente descubra relações e padrões que poderíamos não antecipar inicialmente.\n",
    "\n",
    "6. Desafio realista para o modelo: Trabalhar com dados não processados cria um cenário mais próximo do mundo real, desafiando nosso modelo a lidar com a complexidade e variabilidade inerentes aos dados musicais.\n",
    "\n",
    "Ao adiar a seleção de features, estamos nos dando a oportunidade de explorar diversas abordagens de modelagem e técnicas de seleção de características. Isso pode incluir métodos como:\n",
    "\n",
    "- Análise de correlação entre features e a variável alvo (popularidade)\n",
    "- Técnicas de seleção de features baseadas em importância (como as fornecidas por modelos de árvore)\n",
    "- Métodos de redução de dimensionalidade (como PCA ou t-SNE)\n",
    "- Testes de diferentes combinações de features em modelos preliminares\n",
    "\n",
    "Esta abordagem nos permite ser mais metódicos e baseados em evidências em nossas decisões sobre quais características incluir em nosso modelo final. Também nos dá a flexibilidade de adaptar nossa estratégia conforme ganhamos mais insights sobre os dados e o problema em questão.\n",
    "\n",
    "Nosso próximo passo será iniciar uma análise exploratória mais aprofundada dos dados, buscando entender melhor as relações entre as diferentes características e a popularidade das músicas. Isso nos ajudará a informar nossas decisões futuras sobre seleção de features e escolha de modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Codificação de Variáveis Categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_and_encode_dataset(df, target, n_splits=5):\n",
    "    encoded_df = df.copy()\n",
    "    encoding_dict = {}\n",
    "    scaler_dict = {}\n",
    "\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    \n",
    "    for column in df.columns:\n",
    "        if column == target:\n",
    "            continue\n",
    "        \n",
    "        encoded = np.zeros(len(df))\n",
    "        column_dict = {}\n",
    "        \n",
    "        # Target encoding\n",
    "        for train_idx, val_idx in kf.split(df):\n",
    "            target_means = df.iloc[train_idx].groupby(column)[target].mean()\n",
    "            encoded[val_idx] = df[column].iloc[val_idx].map(target_means)\n",
    "            \n",
    "            column_dict.update(target_means.to_dict())\n",
    "        \n",
    "        global_mean = df[target].mean()\n",
    "        encoded = np.where(np.isnan(encoded), global_mean, encoded)\n",
    "        \n",
    "        column_dict['_global_mean'] = global_mean\n",
    "        encoding_dict[column] = column_dict\n",
    "        \n",
    "        # Normalization\n",
    "        scaler = StandardScaler()\n",
    "        normalized = scaler.fit_transform(encoded.reshape(-1, 1)).flatten()\n",
    "        \n",
    "        encoded_df[f\"{column}_encoded_normalized\"] = normalized\n",
    "        scaler_dict[column] = scaler\n",
    "    \n",
    "    return encoded_df, encoding_dict, scaler_dict\n",
    "\n",
    "def apply_normalize_and_encode(df, encoding_dict, scaler_dict):\n",
    "    encoded_df = df.copy()\n",
    "    \n",
    "    for column, column_dict in encoding_dict.items():\n",
    "        if column in df.columns:\n",
    "            global_mean = column_dict['_global_mean']\n",
    "            \n",
    "            # Apply target encoding\n",
    "            encoded = df[column].map(column_dict)\n",
    "            encoded = encoded.fillna(global_mean)\n",
    "            \n",
    "            # Apply normalization\n",
    "            scaler = scaler_dict[column]\n",
    "            normalized = scaler.transform(encoded.values.reshape(-1, 1)).flatten()\n",
    "            \n",
    "            encoded_df[f\"{column}_encoded_normalized\"] = normalized\n",
    "        else:\n",
    "            print(f\"Warning: Column '{column}' not found in the input DataFrame.\")\n",
    "    \n",
    "    return encoded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df_treating_data.copy()\n",
    "new_df = new_df.drop(columns=['track_unique_id', 'track_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_df, encoding_dict, scaler_dict = normalize_and_encode_dataset(new_df, 'popularity_target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_df = encoded_df.drop(columns=['artists', 'album_name', 'track_name', 'duration_ms', 'explicit', 'danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'time_signature', 'track_genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = encoded_df.drop('popularity_target', axis=1)\n",
    "y = encoded_df['popularity_target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['artists_album_track'] = X['artists_encoded_normalized'] * X['album_name_encoded_normalized'] * X['track_name_encoded_normalized']\n",
    "X = X.drop(columns=['instrumentalness_encoded_normalized', 'duration_ms_encoded_normalized', 'key_encoded_normalized', 'loudness_encoded_normalized', 'mode_encoded_normalized', 'time_signature_encoded_normalized', 'explicit_encoded_normalized'])\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_temp_df_no_genres, X_test_df_no_genres, y_temp_df_no_genres, y_test_df_no_genres = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_df_no_genres, X_val_df_no_genres, y_train_df_no_genres, y_val_df_no_genres = train_test_split(X_temp_df_no_genres, y_temp_df_no_genres, test_size=0.25, random_state=42)\n",
    "\n",
    "print(f\"Tamanho do conjunto de treino: {len(X_train_df_no_genres)}\")\n",
    "print(f\"Tamanho do conjunto de validação: {len(X_val_df_no_genres)}\")\n",
    "print(f\"Tamanho do conjunto de teste: {len(X_test_df_no_genres)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(random_state=42)\n",
    "\n",
    "lgb_model = lgb.LGBMClassifier(random_state=42)\n",
    "\n",
    "logistic_model = LogisticRegression(random_state=42)\n",
    "\n",
    "etc_model = ExtraTreesClassifier(random_state=42)\n",
    "\n",
    "gbc_model = GradientBoostingClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_rf = {\n",
    "    'n_estimators': randint(100, 1000),\n",
    "    'max_depth': [None] + list(range(5, 31)),\n",
    "    'min_samples_split': randint(2, 20),\n",
    "    'min_samples_leaf': randint(1, 20),\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': randint(100, 1000),\n",
    "    'max_depth': randint(3, 15),\n",
    "    'learning_rate': uniform(0.01, 0.3),\n",
    "    'subsample': uniform(0.6, 0.4),\n",
    "    'colsample_bytree': uniform(0.6, 0.4)\n",
    "}\n",
    "\n",
    "param_grid_lgb = {\n",
    "    'n_estimators': randint(100, 1000),\n",
    "    'max_depth': randint(3, 15),\n",
    "    'learning_rate': uniform(0.01, 0.3),\n",
    "    'subsample': uniform(0.6, 0.4),\n",
    "    'colsample_bytree': uniform(0.6, 0.4)\n",
    "}\n",
    "\n",
    "param_grid_logistic = {\n",
    "    'C': uniform(0.1, 10),\n",
    "    'penalty': ['l1', 'l2', 'elasticnet'],\n",
    "    'solver': ['saga'],\n",
    "    'l1_ratio': uniform(0, 1)\n",
    "}\n",
    "\n",
    "param_grid_etc = {\n",
    "    'n_estimators': randint(100, 1000),\n",
    "    'max_depth': [None] + list(range(5, 31)),\n",
    "    'min_samples_split': randint(2, 20),\n",
    "    'min_samples_leaf': randint(1, 20),\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "param_grid_gbc = {\n",
    "    'n_estimators': randint(100, 1000),\n",
    "    'learning_rate': uniform(0.01, 0.3),\n",
    "    'max_depth': randint(3, 15),\n",
    "    'min_samples_split': randint(2, 20),\n",
    "    'min_samples_leaf': randint(1, 20),\n",
    "    'subsample': uniform(0.6, 0.4)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    (rf_classifier, param_grid_rf, 'Random Forest'),\n",
    "    (xgb_model, param_grid_xgb, 'XGBoost'),\n",
    "    (lgb_model, param_grid_lgb, 'LightGBM'),\n",
    "    (logistic_model, param_grid_logistic, 'Logistic Regression'),\n",
    "    (etc_model, param_grid_etc, 'Extra Trees'),\n",
    "    (gbc_model, param_grid_gbc, 'Gradient Boosting')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_scorer = make_scorer(accuracy_score)\n",
    "\n",
    "best_params = {}\n",
    "best_scores = {}\n",
    "for model, param_grid, name in models:\n",
    "    print(f\"Tuning {name}...\")\n",
    "    rs = RandomizedSearchCV(model, param_grid, n_iter=100, cv=5, n_jobs=-1, random_state=42, verbose=1, scoring=accuracy_scorer)\n",
    "    rs.fit(X_train_df_no_genres, y_train_df_no_genres)\n",
    "    best_params[name] = rs.best_params_\n",
    "    best_scores[name] = rs.best_score_\n",
    "\n",
    "for name in best_params.keys():\n",
    "    print(f\"\\nBest parameters for {name}:\")\n",
    "    for param, value in best_params[name].items():\n",
    "        print(f\"    {param}: {value}\")\n",
    "    print(f\"Best accuracy for {name}: {best_scores[name]:.4f}\")\n",
    "\n",
    "best_model = max(best_scores, key=best_scores.get)\n",
    "print(f\"\\nOverall best model: {best_model}\")\n",
    "print(f\"Best overall accuracy: {best_scores[best_model]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best parameters for Random Forest:\n",
    "\n",
    "1. max_depth: 24\n",
    "2. max_features: log2\n",
    "3. min_samples_leaf: 1\n",
    "4. min_samples_split: 4\n",
    "5. n_estimators: 227\n",
    "\n",
    "- Best accuracy for Random Forest: 0.9055\n",
    "\n",
    "Best parameters for XGBoost:\n",
    "\n",
    "1. colsample_bytree: 0.679486272613669\n",
    "2. learning_rate: 0.01165663513708072\n",
    "3. max_depth: 13\n",
    "4. n_estimators: 598\n",
    "5. subsample: 0.8827429375390468\n",
    "\n",
    "- Best accuracy for XGBoost: 0.9066\n",
    "\n",
    "Best parameters for LightGBM:\n",
    "\n",
    "1. colsample_bytree: 0.8732027093665427\n",
    "2. learning_rate: 0.031356594538068695\n",
    "3. max_depth: 10\n",
    "4. n_estimators: 704\n",
    "5. subsample: 0.9379501243877818\n",
    "\n",
    "- Best accuracy for LightGBM: 0.9061\n",
    "\n",
    "Best parameters for Logistic Regression:\n",
    "\n",
    "1. C: 6.274815096277165\n",
    "2. l1_ratio: 0.6116531604882809\n",
    "3. penalty: l1\n",
    "4. solver: saga\n",
    "\n",
    "- Best accuracy for Logistic Regression: 0.8971\n",
    "\n",
    "Best parameters for Extra Trees:\n",
    "\n",
    "1. max_depth: 24\n",
    "2. max_features: log2\n",
    "3. min_samples_leaf: 1\n",
    "4. min_samples_split: 4\n",
    "5. n_estimators: 227\n",
    "\n",
    "- Best accuracy for Extra Trees: 0.9044\n",
    "\n",
    "Best parameters for Gradient Boosting:\n",
    "    \n",
    "1. learning_rate: 0.08323765667433225\n",
    "2. max_depth: 13\n",
    "3. min_samples_leaf: 9\n",
    "4. min_samples_split: 18\n",
    "5. n_estimators: 929\n",
    "6. subsample: 0.9887128330883843\n",
    "\n",
    "- Best accuracy for Gradient Boosting: 0.9078\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier = RandomForestClassifier(random_state=42, max_depth=24, max_features='log2', min_samples_leaf=1, min_samples_split=4, n_estimators=227)\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(random_state=42, colsample_bytree=0.679486272613669, learning_rate=0.01165663513708072, max_depth=13, n_estimators=598, subsample=0.8827429375390468)\n",
    "\n",
    "lgb_model = lgb.LGBMClassifier(random_state=42, colsample_bytree=0.8732027093665427, learning_rate=0.031356594538068695, max_depth=10, n_estimators=704,\n",
    "subsample=0.9379501243877818)\n",
    "\n",
    "logistic_model = LogisticRegression(random_state=42, C=6.274815096277165, l1_ratio=0.6116531604882809, penalty='l1', solver='saga')\n",
    "\n",
    "etc_model = ExtraTreesClassifier(random_state=42, max_depth=24, max_features='log2', min_samples_leaf=1, min_samples_split=4, n_estimators=227)\n",
    "\n",
    "gbc_model = GradientBoostingClassifier(random_state=42, learning_rate=0.08323765667433225, max_depth=13, min_samples_leaf=9, min_samples_split=18, n_estimators=929, subsample=0.9887128330883843)\n",
    "\n",
    "svc_model = SVC(random_state=42, C=1, kernel='rbf')\n",
    "\n",
    "ada_clf = AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=10), n_estimators=500, learning_rate=0.01, random_state=42)\n",
    "\n",
    "hist_gbc = HistGradientBoostingClassifier(max_iter=100, random_state=42, early_stopping=True, l2_regularization=0.1, learning_rate=0.1, max_bins=255, max_depth=20, min_samples_leaf=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_model = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('lgb_model', lgb_model),\n",
    "        ('xgb_model', xgb_model),\n",
    "        ('gbc_model', gbc_model),\n",
    "    ],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "voting_model.fit(X_train_df_no_genres, y_train_df_no_genres)\n",
    "\n",
    "y_pred_val = voting_model.predict(X_val_df_no_genres)\n",
    "y_pred_test = voting_model.predict(X_test_df_no_genres)\n",
    "\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val_df_no_genres, y_pred_val))\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test_df_no_genres, y_pred_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_target_encoding = df_test.copy()\n",
    "df_test_target_encoding = df_test_target_encoding.drop(columns=['track_unique_id', 'track_id'])\n",
    "\n",
    "df_test_target_encoding['tempo'] = df_test_target_encoding['tempo'].replace(0,tempo_median)\n",
    "df_test_target_encoding['time_signature'] = df_test_target_encoding['time_signature'].replace(0,4)\n",
    "\n",
    "df_test_target_encoding = apply_normalize_and_encode(df_test_target_encoding, encoding_dict, scaler_dict)\n",
    "\n",
    "df_test_target_encoding['artists_album_track'] = df_test_target_encoding['artists_encoded_normalized'] * df_test_target_encoding['album_name_encoded_normalized'] * df_test_target_encoding['track_name_encoded_normalized']\n",
    "\n",
    "df_test_target_encoding = df_test_target_encoding.drop(columns=['artists', 'album_name', 'track_name', 'duration_ms', 'explicit', 'danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'time_signature', 'track_genre', 'instrumentalness_encoded_normalized', 'duration_ms_encoded_normalized', 'key_encoded_normalized', 'loudness_encoded_normalized', 'mode_encoded_normalized', 'time_signature_encoded_normalized', 'explicit_encoded_normalized'])\n",
    "\n",
    "predict_target_encoding_stacking = voting_model.predict(df_test_target_encoding)\n",
    "result_stacking = pd.DataFrame({ 'track_unique_id': df_test['track_unique_id'], 'popularity_target': predict_target_encoding_stacking })\n",
    "result_stacking.to_csv('result_voting.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
