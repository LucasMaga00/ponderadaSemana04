{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiro, vamos realizar a importação de todas as bibliotecas que usaremos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1297,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures, normalize, LabelEncoder\n",
    "from sklearn.model_selection import KFold, train_test_split, RandomizedSearchCV, GridSearchCV, cross_val_predict, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, make_scorer\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, StackingClassifier, GradientBoostingClassifier, ExtraTreesClassifier, BaggingClassifier, AdaBoostClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, Lasso, RidgeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, vamos importar nossos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1298,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('../test.csv')\n",
    "df = pd.read_csv('../train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1299,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None) # Configuracao para mostrar todas as colunas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entendendo o significado de todas as colunas\n",
    "\n",
    "É de extrema importância entender todas as colunas, por isso, vamos copiar e colar o significado delas:\n",
    "\n",
    "- track_id: O ID único de cada música\n",
    "    \n",
    "- artists: Nome dos(as) artistas que performaram a música, separados por ';'\n",
    "    \n",
    "- album_name: Nome do álbum no qual aparece a música\n",
    "    \n",
    "- track_name: Nome da música\n",
    "    \n",
    "- duration_ms: A duração da música em milissegundos\n",
    "    \n",
    "- explicit: Boolean indicando se a música possui conteúdo explícito\n",
    "    \n",
    "- danceability: Descreve quanto uma música é \"dançante\" (0.0 = menos dançante, 1.0 = mais dançante)\n",
    "    \n",
    "- energy: Representa a intensidade e atividade de uma música (0.0 = baixa energia, 1.0 = alta energia)\n",
    "    \n",
    "- key: A tonalidade musical da faixa mapeada usando a notação padrão de Classe de Altura (12 notas musicais)\n",
    "    \n",
    "- loudness: Nível geral de volume da faixa em decibéis (dB)\n",
    "    \n",
    "- mode: Indica a modalidade (maior ou menor) da faixa\n",
    "    \n",
    "- speechiness: Detecta a presença de palavras faladas na faixa\n",
    "    \n",
    "- acousticness: Medida de confiança sobre se a faixa é acústica (0,0 = não acústica, 1,0 = altamente acústica)\n",
    "    \n",
    "- instrumentalness: Prediz se uma faixa contém vocais (0,0 = contém vocais, 1,0 = instrumental)\n",
    "    \n",
    "- liveness: Detecta a presença de uma audiência na gravação (0,0 = gravação em estúdio, 1,0 = performance ao vivo)\n",
    "    \n",
    "- valence: Mede a positividade musical transmitida por uma faixa (0,0 = negativa, 1,0 = positiva)\n",
    "    \n",
    "- tempo: Tempo estimado da faixa em batidas por minuto (BPM)\n",
    "    \n",
    "- time_signature: Assinatura de tempo estimada da faixa (de 3 a 7)\n",
    "    \n",
    "- track_genre: O gênero da música\n",
    "    \n",
    "- popularity_target: Boolean indicando se a música é popular ou não\n",
    "\n",
    "Realizando a análise das colunas, fiquei em dúvida sobre a diferença entre a coluna 'tempo' e 'time_signature'. Por isso, realizei uma análise mais profunda no significado delas:\n",
    "\n",
    "* tempo (Batidas por minuto):\n",
    "   * O tempo representa a velocidade ou ritmo de uma faixa, medido em batidas por minuto (BPM).\n",
    "   * O tempo médio é de cerca de 122 BPM, o que representa um ritmo moderado e enérgico.\n",
    "   * O tempo mínimo é 0 BPM (o que pode indicar dados ausentes ou faixas muito lentas), e o máximo é cerca de 223 BPM (muito rápido).\n",
    "\n",
    "* time_signature (Fórmula de compasso):\n",
    "   * A fórmula de compasso representa a estrutura rítmica de uma faixa, indicando quantas batidas existem em cada compasso e qual valor de nota representa uma batida.\n",
    "   * Os valores geralmente variam de 3 a 7, sendo 4 o mais comum (representando o compasso 4/4, que é padrão em muitos gêneros).\n",
    "   * A partir das estatísticas, podemos ver que a mediana e os percentis 25 e 75 são 4, confirmando que o compasso 4/4 é realmente o mais comum.\n",
    "   * O mínimo de 0 pode indicar dados ausentes ou fórmulas de compasso não convencionais.\n",
    "\n",
    "   Primeiro dou uma olhada por cima dos dados apenas para entender quais colunas são númericas e categóricas. Também tenho a intenção de ver elas como dados reais e por isso chamo o comando `df.head(3)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora partindo para uma análise mais profunda das colunas numéricas, começo com uma análise da estatística descritiva de cada coluna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com o output acima, já é possível observar que valores iguais a 0 em 'tempo' e 'time_signature' provavelmente são missing values. Chegamos a essa conclusão porque músicas com 0 BPM não existem, mesmo muito lentas. E 'time_sigture' já comenta na definição das colunas que os valores vão de 3 a 7, ou seja, 0 é incorreto. Não realizamos a correção desses valores faltantes nesse exato momento, mas em breve voltaremos com eles.\n",
    "\n",
    "## Exploração e Visualização dos Dados\n",
    "\n",
    "Agora, na intenção de entender os dados e descobrir padrões, vamos realizar uma exploração e visualização dos dados! Para isso, vamos utilizar bibliotecas como Matplot e Seaborn. Nossa missão aqui é descobrir padrões, correlações e tendências nos dados. Vamos usar visualizações eficazes para comunicar os insights e justificar nossas futuras escolhas de features e modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1303,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo um estilo para nossos graficos e alterando o tamanho padrão das figuras geradas pelo Matplotlib\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para o começo da nossa análise, é importante saber a quantidade de músicas que são populares ou não e saber como está a distribuição entre elas. No gráfico gerado a seguir, é possível observar que existe uma divisão bem harmoniosa entre músicas populares e não populares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='popularity_target', data=df)\n",
    "plt.title('Distribution of Song Popularity')\n",
    "plt.xlabel('Popularity (0: Not Popular, 1: Popular)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partindo com nossa análise, vamos agora observar nossas variáveis numéricas e a relação entre elas. O Heatmap é um gráfico perfeito para isso que demonstra as relações entre as colunas. Resumindo bastante funciona da forma a seguir: \n",
    "\n",
    "Os valores de correlação variam de -1 a 1:\n",
    "\n",
    "- **+1**: Correlação positiva perfeita. À medida que uma variável aumenta, a outra também aumenta.\n",
    "- **-1**: Correlação negativa perfeita. À medida que uma variável aumenta, a outra diminui.\n",
    "- **0**: Nenhuma correlação. As duas variáveis não afetam uma à outra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = ['duration_ms', 'danceability', 'energy', 'key', 'loudness', 'speechiness', \n",
    "                      'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(df[numerical_features].corr(), annot=True, cmap='coolwarm', linewidths=0.5)\n",
    "plt.title('Correlation Heatmap of Numerical Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizando a análise do Heatmap acima, é possível identificar alguns padrões importantes sobre nossa base de dados.\n",
    "\n",
    "1. Correlação forte entre 'energy' e 'loudness': Existe uma correlação positiva forte (0.76) entre 'energy' e 'loudness', indicando que músicas mais enérgicas tendem a ser mais altas.\n",
    "\n",
    "2. Correlação negativa entre 'acousticness' e 'energy': Há uma forte correlação negativa (-0.73) entre 'acousticness' e 'energy', sugerindo que músicas mais acústicas tendem a ser menos enérgicas.\n",
    "\n",
    "3. Correlação negativa entre 'acousticness' e 'loudness': Similarmente, existe uma correlação negativa moderada (-0.59) entre 'acousticness' e 'loudness', indicando que músicas acústicas tendem a ser menos altas.\n",
    "\n",
    "4. Correlação positiva entre 'danceability' e 'valence': Há uma correlação positiva moderada (0.48) entre 'danceability' e 'valence', sugerindo que músicas mais dançantes tendem a ter um tom emocional mais positivo.\n",
    "\n",
    "5. Correlação negativa entre 'instrumentalness' e 'loudness': Observa-se uma correlação negativa moderada (-0.43) entre 'instrumentalness' e 'loudness', indicando que músicas mais instrumentais tendem a ser menos altas.\n",
    "\n",
    "6. Pouca correlação com 'duration_ms': A 'duration_ms' tem correlações fracas com a maioria das outras características, sugerindo que o comprimento da música não está fortemente relacionado com suas outras propriedades acústicas.\n",
    "\n",
    "7. Correlações fracas com 'key': A 'key' tem correlações muito fracas com outras características, indicando que não há uma relação forte entre a tonalidade e outros aspectos musicais neste conjunto de dados.\n",
    "\n",
    "8. Correlações moderadas com 'valence': A 'valence' tem correlações moderadas positivas com 'danceability' (0.48) e 'energy' (0.26), sugerindo que músicas mais positivas tendem a ser mais dançantes e enérgicas.\n",
    "\n",
    "9. Pouca correlação entre 'tempo' e outras características: O 'tempo' da música tem correlações relativamente fracas com outras características, com a mais forte sendo com 'energy' (0.24).\n",
    "\n",
    "10. Correlação fraca entre 'speechiness' e outras características: 'Speechiness' tem correlações geralmente fracas com outras características, com a mais notável sendo com 'liveness' (0.21).\n",
    "\n",
    "11. 'Liveness' tem correlações fracas: A característica 'liveness' não mostra correlações fortes com nenhuma outra característica, sugerindo que é relativamente independente das outras propriedades musicais.\n",
    "\n",
    "Saber desses padrão será importante para quando começarmos a selecionar as features para o treinamento do nosso modelo! Porque aqui é possível observar que alguns colunas estão extremamente ligadas com outras.\n",
    "\n",
    "Agora, queremos entender como diferentes características musicais se relacionam com a popularidade das músicas. Por isso, vamos criar alguns gráficos para realizar essa visualização.\n",
    "\n",
    "Com essa análise, vamos identificar quais características musicais têm maior influência na popularidade de uma música."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "features = ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', 'instrumentalness']\n",
    "for i, feature in enumerate(features):\n",
    "    sns.boxplot(x='popularity_target', y=feature, data=df, ax=axes[i//3][i%3])\n",
    "    axes[i//3][i%3].set_title(f'{feature.capitalize()} by Popularity')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observando o gráfico acima, conseguimos ter alguns insights.\n",
    "\n",
    "1. Danceability (Dançabilidade):\n",
    "\n",
    "Há uma ligeira tendência de músicas populares (1) terem maior dançabilidade.\n",
    "A diferença é pequena, mas notável, o que sugere que músicas mais dançantes têm uma probabilidade um pouco maior de serem populares.\n",
    "\n",
    "2.Instrumentalness (Instrumentalidade):\n",
    "\n",
    "Músicas populares tendem a ter menor instrumentalidade.\n",
    "Isso sugere que músicas com vocais são geralmente mais populares do que músicas puramente instrumentais.\n",
    "\n",
    "Agora, para entender quais gêneros proporcionam mais sucessos às músicas, vamos criar um gráfico para visualizar os 10 melhores gêneros em termos de músicas populares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_genres = df['track_genre'].value_counts().nlargest(10)\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=top_genres.index, y=top_genres.values)\n",
    "plt.title('Top 10 Genres by Count')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "sns.scatterplot(data=df, x='energy', y='danceability', hue='popularity_target', palette='viridis')\n",
    "plt.title('Energy vs. Danceability (Colored by Popularity)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Análisando o gráfico acima, podemos observar que a popularidade não parece ser exclusivamente determinada por altos níveis de energia e dançabilidade, já que músicas populares existem em diversos níveis de energia e dançabilidade, sugerindo que outros fatores também influenciam a popularidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(data=df, x='duration_ms', bins=50, kde=True)\n",
    "plt.title('Distribution of Song Durations')\n",
    "plt.xlabel('Duration (ms)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observando a duração das músicas, podemos observar que há uma concentração muito alta de músicas com duração menor. Também observamos que existem músicas com durações extremamente longas. Estes podem ser álbuns inteiros, performances ao vivo, ou erros nos dados.\n",
    "\n",
    "- A assimetria da distribuição pode afetar análises estatísticas, sendo necessário considerar transformações ou métodos robustos. Em breve voltaremos nesse tópico ao tratar os dados.\n",
    "\n",
    "Já o gráfico de barras empilhadas abaixo apresenta uma comparação visual da proporção de conteúdo explícito entre músicas populares e não populares "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explicit_by_popularity = df.groupby('popularity_target')['explicit'].value_counts(normalize=True).unstack()\n",
    "explicit_by_popularity.plot(kind='bar', stacked=True)\n",
    "plt.title('Proportion of Explicit Content by Popularity')\n",
    "plt.xlabel('Popularity')\n",
    "plt.ylabel('Proportion')\n",
    "plt.legend(title='Explicit', loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observando o gráfico acima, podemos observar que:\n",
    "\n",
    "1. A maioria das músicas, tanto populares quanto não populares, não contém conteúdo explícito.\n",
    "2. Há uma ligeira tendência de músicas populares terem uma proporção um pouco maior de conteúdo explícito em comparação com as não populares.\n",
    "3. A presença de conteúdo explícito não parece ser um fator determinante para a popularidade de uma música, dada a pequena diferença observada.\n",
    "\n",
    "Agora para fechar nossa análise, vamos comparar a distribuição da duração das músicas entre as categorias de popularidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxenplot(x='popularity_target', y='duration_ms', data=df)\n",
    "plt.title('Song Duration Distribution by Popularity')\n",
    "plt.xlabel('Popularity (0: Not Popular, 1: Popular)')\n",
    "plt.ylabel('Duration (ms)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observando o gráfico acima, vemos que:\n",
    "\n",
    "1. As medianas de duração para músicas populares e não populares são muito semelhantes, sugerindo que a duração por si só não é um forte indicador de popularidade.\n",
    "2. A dispersão (representada pelo tamanho das caixas) é ligeiramente menor para músicas populares, indicando uma maior consistência na duração dessas faixas.\n",
    "3. Existem muitos outliers em ambas as categorias, representando músicas com durações excepcionalmente longas.\n",
    "4. As músicas populares parecem ter menos outliers extremos em comparação com as não populares, especialmente na faixa de duração mais longa.\n",
    "5. A maioria das músicas, independentemente da popularidade, tem duração dentro de um intervalo relativamente estreito, como evidenciado pelo tamanho das caixas do boxplot.\n",
    "6. Há uma leve tendência de músicas populares terem durações um pouco mais curtas, observável pela posição ligeiramente inferior da caixa para músicas populares.\n",
    "\n",
    "Os insights mais importantes que encontramos em nossa análise incluem: a ligeira tendência de músicas populares terem maior energia e dançabilidade; a predominância de conteúdo não explícito em ambas as categorias de popularidade, com uma sutil inclinação para mais conteúdo explícito em músicas populares; e a observação de que a duração das músicas não é um forte indicador de popularidade, embora músicas populares tendam a ter durações mais consistentes. Além disso, notamos correlações significativas entre certas características musicais, como a relação positiva entre energia e volume (loudness), e negativa entre acústica e energia.\n",
    "\n",
    "Ainda é muito cedo para entrarmos na escolha das features para nosso modelo, mas já é possível observar que não existe uma coluna em específica que determina a popularidade das músicas, com isso, é bastante provável que vamos utilizar todas as colunas para treinar nosso modelo, excluindo apenas as colunas de identificação.\n",
    "\n",
    "## Formulação de Hipóteses\n",
    "\n",
    "#### Hipótese 01: Influência da dançabilidade na era do TikTok\n",
    "\n",
    "Com a popularização do TikTok, onde coreografias virais são frequentes, músicas mais dançantes podem ter maior probabilidade de se tornarem populares. Esta hipótese sugere uma correlação positiva entre a dançabilidade de uma música e sua popularidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(2, 2, 1)\n",
    "sns.boxplot(x='popularity_target', y='danceability', data=df)\n",
    "plt.title('Dançabilidade vs. Popularidade')\n",
    "plt.xlabel('Popularidade (0: Não Popular, 1: Popular)')\n",
    "plt.ylabel('Dançabilidade')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É possível observar que a média de músicas dançantes é um pouco mais alto para músicas populares, mas a diferença não é tão grande assim, logo, não indica extrema importância se a música é dançante ou não para ela ser popular.\n",
    "\n",
    "#### Hipótese 02: Conteúdo explícito em músicas de temática triste\n",
    "\n",
    "Músicas categorizadas como \"sad\" ou emocionalmente intensas podem ter uma maior tendência a conter conteúdo explícito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(2, 2, 2)\n",
    "sad_genres = ['sad', 'melancholic', 'emotional']  # Ajuste conforme necessário\n",
    "df['is_sad'] = df['track_genre'].isin(sad_genres)\n",
    "sns.barplot(x='is_sad', y='explicit', data=df)\n",
    "plt.title('Conteúdo Explícito em Músicas Tristes vs. Outras')\n",
    "plt.xlabel('Gênero Triste')\n",
    "plt.ylabel('Proporção de Conteúdo Explícito')\n",
    "df = df.drop(columns='is_sad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É possível observar que o conteúdo explícito está extremamente presente em músicas classificadas como 'sad', 'melancholic' ou 'emotional'. Comprovando nossa hipótese.\n",
    "\n",
    "#### Hipótese 03: Popularidade de músicas com temática melancólica\n",
    "\n",
    "Músicas classificadas como 'sad' estão entre as mais populares, principalmente porque hoje a depressão é o problema do século."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_genres = df['track_genre'].value_counts().nlargest(10)\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=top_genres.index, y=top_genres.values)\n",
    "plt.title('Top 10 Genres by Count')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É possível ver que o gênero 'sad' é o segundo gênero com maior sucesso de músicas populares. Comprovando nossa hipótese.\n",
    "\n",
    "#### Hipótese 04: Relação inversa entre instrumentalidade e popularidade\n",
    "\n",
    "Músicas com alto grau de instrumentalidade (pouco ou nenhum vocal) podem tender a ser menos populares, possivelmente devido à preferência do público mainstream por músicas com letras e vozes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(2, 2, 4)\n",
    "sns.boxplot(x='popularity_target', y='instrumentalness', data=df)\n",
    "plt.title('Instrumentalidade vs. Popularidade')\n",
    "plt.xlabel('Popularidade (0: Não Popular, 1: Popular)')\n",
    "plt.ylabel('Instrumentalidade')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É possível observar que existem músicas populares e que são instrumentais, mas, em maioria, elas são classificadas como não populares. Comprovando nossa hipótese.\n",
    "\n",
    "## Limpeza e Tratamento de Valores Nulos\n",
    "\n",
    "### Tratamento de valores duplicados\n",
    "\n",
    "Fazer a limpeza de valores duplicados é importantes pois valores duplicados podem prejudicar no aprendizado do nosso algoritmo. Para realizar a limpeza, vamos primeiro checar se existem valores duplicados e caso existirem, vamos excluir todos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicated_values = df[df.duplicated()]\n",
    "print(len(duplicated_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver acima, não existem valores duplicados. Assim, seguiremos com nossa análise\n",
    "\n",
    "### Tratamento de missing values\n",
    "\n",
    "Missing values são valores = null\n",
    "\n",
    "É importante verificar a existência deles e resolver os valores faltantes caso existam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver acima, também não existem valores faltantes.\n",
    "\n",
    "Agora, vamos verificar valores que são iguais a 0. Como identificamos lá no começo desse notebook, já sabemos de alguns valores que não deveriam estar iguais a 0. Também vamos procurar por novos valores iguais a 0 e que não deveriam estar assim, caso existam, vamos resolver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_count = (df == 0).sum()\n",
    "print(zero_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver acima, as colunas 'time_signature' e 'tempo' possuem valores iguais a 0 e elas não deveriam estar assim:\n",
    "\n",
    "1. Tempo:\n",
    "\n",
    "- Representa a velocidade da música em batidas por minuto (BPM).\n",
    "- Um valor 0 significaria que não há batidas, o que é musicalmente impossível.\n",
    "- Tempos típicos variam de cerca de 60 BPM (lento) a 200 BPM (muito rápido).\n",
    "\n",
    "\n",
    "2. Time signature (fórmula de compasso):\n",
    "\n",
    "- Indica quantas batidas há por compasso e qual nota representa uma batida.\n",
    "- É escrita como uma fração, por exemplo, 4/4 ou 3/4.\n",
    "- Um valor 0 não faria sentido, pois implicaria em nenhuma batida por compasso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['time_signature'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['tempo'].describe(), df['tempo'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para resolver esses 2 problemas, vamos: \n",
    "\n",
    "- Substituir os valores de 'time_signature' pela moda, que é 4\n",
    "- Substituir os valores de 'tempo' pela mediana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1321,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempo_median = df['tempo'].median()\n",
    "df_treating_data = df.copy()\n",
    "df_treating_data['tempo'] = df_treating_data['tempo'].replace(0,tempo_median)\n",
    "df_treating_data['time_signature'] = df_treating_data['time_signature'].replace(0,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identificação de outliers e correção\n",
    "\n",
    "As colunas que vamos visualizar e depois tratar os outliers são as colunas: 'duration_ms', 'loudness' e 'tempo'.\n",
    "\n",
    "Realizei a escolha dessas três colunas porque todas as outras colunas numéricas se constituem de valores que vâo de 0 a 1. Algumas até possuem outliers mas são features importantes e que quero manter para preservar a pureza dos dados em features que vão de 0 a 1. Mais tarde, vamos minimizar os impactos que esses outliers podem causar com o standardScaler\n",
    "\n",
    "Agora partindo para a identificação dos outliers que escolhemos, vamos começar visualizando em boxplot os possíveis outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=df_treating_data, y='duration_ms')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observando o gráfico acima, é possívei ver que 'duration_ms' possui vários outliers, vamos guardar essa informação e em breve corrigir eles.\n",
    "\n",
    "Agora fazendo a análise dos outliers de 'loudness', vamos desenhar outro boxplot para realizar essa visualização:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=df_treating_data, y='loudness')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora fazendo a análise dos outliers de 'tempo', vamos desenhar outro boxplot para realizar essa visualização:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=df_treating_data, y='tempo')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após uma análise cuidadosa dos dados, incluindo a presença de outliers em colunas como 'duration_ms', 'loudness' e 'tempo', decidimos manter o dataset em seu estado original, sem realizar nenhuma transformação ou exclusão neste momento.\n",
    "\n",
    "Esta decisão se baseia nas seguintes considerações:\n",
    "\n",
    "1. Preservação da integridade dos dados: Cada característica de uma música, mesmo aquelas que parecem estatisticamente atípicas, pode conter informações valiosas sobre a natureza única da faixa e potencialmente sobre sua popularidade.\n",
    "\n",
    "2. Flexibilidade para análises futuras: Manter todos os dados em seu estado original nos proporciona máxima flexibilidade para realizar diversos tipos de análises e experimentos posteriormente.\n",
    "\n",
    "3. Seleção de features posterior: Decidimos adiar a seleção de features para uma etapa posterior do processo. Isso nos permitirá tomar decisões mais informadas sobre quais características são mais relevantes para nosso modelo, baseando-nos em análises mais aprofundadas e experimentos iniciais.\n",
    "\n",
    "4. Captura de padrões complexos: No domínio musical, o que pode parecer um outlier ou uma característica irrelevante pode, na verdade, ser parte de um padrão mais complexo que contribui para a popularidade de uma faixa.\n",
    "\n",
    "5. Abordagem holística: Ao manter todos os dados, estamos adotando uma visão holística do problema, permitindo que nosso modelo potencialmente descubra relações e padrões que poderíamos não antecipar inicialmente.\n",
    "\n",
    "6. Desafio realista para o modelo: Trabalhar com dados não processados cria um cenário mais próximo do mundo real, desafiando nosso modelo a lidar com a complexidade e variabilidade inerentes aos dados musicais.\n",
    "\n",
    "Ao adiar a seleção de features, estamos nos dando a oportunidade de explorar diversas abordagens de modelagem e técnicas de seleção de características. Isso pode incluir métodos como:\n",
    "\n",
    "- Análise de correlação entre features e a variável alvo (popularidade)\n",
    "- Técnicas de seleção de features baseadas em importância (como as fornecidas por modelos de árvore)\n",
    "- Métodos de redução de dimensionalidade (como PCA ou t-SNE)\n",
    "- Testes de diferentes combinações de features em modelos preliminares\n",
    "\n",
    "Esta abordagem nos permite ser mais metódicos e baseados em evidências em nossas decisões sobre quais características incluir em nosso modelo final. Também nos dá a flexibilidade de adaptar nossa estratégia conforme ganhamos mais insights sobre os dados e o problema em questão.\n",
    "\n",
    "Nosso próximo passo será iniciar uma análise exploratória mais aprofundada dos dados, buscando entender melhor as relações entre as diferentes características e a popularidade das músicas. Isso nos ajudará a informar nossas decisões futuras sobre seleção de features e escolha de modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Codificação de Variáveis Categóricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importância da Codificação\n",
    "\n",
    "A codificação de variáveis categóricas é um passo crucial no pré-processamento de dados para modelos de machine learning. Sua importância se deve a vários fatores:\n",
    "\n",
    "1. **Compatibilidade com algoritmos**: Muitos algoritmos de ML trabalham apenas com valores numéricos. A codificação transforma dados categóricos em formatos numéricos compatíveis.\n",
    "\n",
    "2. **Preservação de informações**: Uma codificação eficaz preserva a informação contida nas categorias, permitindo que o modelo aprenda padrões relevantes.\n",
    "\n",
    "3. **Melhoria do desempenho**: Uma codificação adequada pode melhorar significativamente o desempenho do modelo, capturando relações importantes nos dados.\n",
    "\n",
    "4. **Tratamento de novas categorias**: Ajuda a lidar com categorias não vistas durante o treinamento, um problema comum em dados do mundo real.\n",
    "\n",
    "### Explicação das Funções de Codificação\n",
    "\n",
    "#### Função `normalize_and_encode_dataset`\n",
    "\n",
    "Esta função é usada para codificar e normalizar o conjunto de dados de treinamento.\n",
    "\n",
    "##### Processo:\n",
    "\n",
    "1. **Target Encoding**: \n",
    "   - Utiliza validação cruzada K-Fold para evitar overfitting.\n",
    "   - Para cada coluna, calcula a média do target para cada categoria.\n",
    "   - Substitui cada categoria pelo valor médio correspondente do target.\n",
    "\n",
    "2. **Tratamento de Valores Ausentes**:\n",
    "   - Usa a média global do target para categorias não vistas.\n",
    "\n",
    "3. **Normalização**:\n",
    "   - Aplica StandardScaler para normalizar os valores codificados.\n",
    "\n",
    "4. **Armazenamento**:\n",
    "   - Salva os dicionários de codificação e os scalers para uso posterior.\n",
    "\n",
    "#### Função `apply_normalize_and_encode`\n",
    "\n",
    "Esta função é usada para aplicar a codificação e normalização ao conjunto de teste.\n",
    "\n",
    "##### Processo:\n",
    "\n",
    "1. **Aplicação da Codificação**:\n",
    "   - Usa o dicionário de codificação gerado na função anterior.\n",
    "   - Mapeia as categorias para seus valores codificados.\n",
    "\n",
    "2. **Tratamento de Novas Categorias**:\n",
    "   - Usa a média global para categorias não vistas no treinamento.\n",
    "\n",
    "3. **Normalização**:\n",
    "   - Aplica os mesmos scalers usados no conjunto de treinamento.\n",
    "\n",
    "### Vantagens desta Abordagem\n",
    "\n",
    "1. **Redução de Overfitting**: O uso de validação cruzada na codificação do conjunto de treinamento ajuda a prevenir overfitting.\n",
    "\n",
    "2. **Consistência**: Garante que a codificação seja consistente entre os conjuntos de treinamento e teste.\n",
    "\n",
    "3. **Flexibilidade**: Pode lidar com novas categorias no conjunto de teste.\n",
    "\n",
    "4. **Normalização Integrada**: Combina codificação e normalização em um único processo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1325,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_and_encode_dataset(df, target, n_splits=5):\n",
    "    encoded_df = df.copy()\n",
    "    encoding_dict = {}\n",
    "    scaler_dict = {}\n",
    "\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "   \n",
    "    for column in df.columns:\n",
    "        if column == target:\n",
    "            continue\n",
    "       \n",
    "        encoded = np.zeros(len(df))\n",
    "        column_dict = {}\n",
    "       \n",
    "        # Target encoding\n",
    "        for train_idx, val_idx in kf.split(df):\n",
    "            target_means = df.iloc[train_idx].groupby(column)[target].mean()\n",
    "            encoded[val_idx] = df[column].iloc[val_idx].map(target_means)\n",
    "           \n",
    "            column_dict.update(target_means.to_dict())\n",
    "       \n",
    "        global_mean = df[target].mean()\n",
    "        encoded = np.where(np.isnan(encoded), global_mean, encoded)\n",
    "       \n",
    "        column_dict['_global_mean'] = global_mean\n",
    "        encoding_dict[column] = column_dict\n",
    "       \n",
    "        # Normalization\n",
    "        scaler = StandardScaler()\n",
    "        normalized = scaler.fit_transform(encoded.reshape(-1, 1)).flatten()\n",
    "       \n",
    "        encoded_df[f\"{column}_encoded_normalized\"] = normalized\n",
    "        scaler_dict[column] = scaler\n",
    "   \n",
    "    return encoded_df, encoding_dict, scaler_dict\n",
    "\n",
    "\n",
    "def apply_normalize_and_encode(df, encoding_dict, scaler_dict):\n",
    "    encoded_df = df.copy()\n",
    "   \n",
    "    for column, column_dict in encoding_dict.items():\n",
    "        if column in df.columns:\n",
    "            global_mean = column_dict['_global_mean']\n",
    "           \n",
    "            # Apply target encoding\n",
    "            encoded = df[column].map(column_dict)\n",
    "            encoded = encoded.fillna(global_mean)\n",
    "           \n",
    "            # Apply normalization\n",
    "            scaler = scaler_dict[column]\n",
    "            normalized = scaler.transform(encoded.values.reshape(-1, 1)).flatten()\n",
    "           \n",
    "            encoded_df[f\"{column}_encoded_normalized\"] = normalized\n",
    "        else:\n",
    "            print(f\"Warning: Column '{column}' not found in the input DataFrame.\")\n",
    "   \n",
    "    return encoded_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seleção de Features\n",
    "\n",
    "Para nosso modelo de previsão de popularidade musical, selecionamos todas as colunas disponíveis, exceto 'track_id' e 'track_unique_id'. Esta abordagem abrangente nos permite capturar uma ampla gama de informações sobre cada faixa. As features selecionadas incluem:\n",
    "\n",
    "1. Metadados: artists, album_name, track_name\n",
    "2. Características de áudio: duration_ms, explicit, danceability, energy, key, loudness, mode, speechiness, acousticness, instrumentalness, liveness, valence, tempo, time_signature\n",
    "3. Categoria: track_genre\n",
    "\n",
    "Justificativa: Cada uma dessas features pode contribuir de maneira única para a popularidade de uma música. Por exemplo, o artista e o álbum podem influenciar a exposição inicial da música, enquanto características de áudio como danceability e energy podem afetar a recepção do público.\n",
    "\n",
    "## Engenharia de Features\n",
    "\n",
    "Para aumentar o poder preditivo do nosso modelo, criamos novas features usando várias técnicas de engenharia. As principais funções utilizadas são:\n",
    "\n",
    "1. `create_audio_interactions`:\n",
    "   - Cria interações entre features de áudio existentes (ex: energy_danceability).\n",
    "   - Gera features compostas como 'intensidade' e 'suavidade'.\n",
    "   - Discretiza features contínuas em bins.\n",
    "   Justificativa: Captura relações não lineares entre as features de áudio, que podem ser cruciais para entender a popularidade.\n",
    "\n",
    "2. `frequency_encoding`:\n",
    "   - Codifica variáveis categóricas com base em sua frequência.\n",
    "   Justificativa: Ajuda o modelo a entender a raridade ou comunalidade de artistas, álbuns e gêneros, que pode ser um fator na popularidade.\n",
    "\n",
    "3. `genre_popularity_encoding`:\n",
    "   - Cria features baseadas na popularidade média, mediana e variabilidade de cada gênero.\n",
    "   Justificativa: Fornece ao modelo informações sobre a tendência de popularidade de diferentes gêneros musicais.\n",
    "\n",
    "4. `create_genre_hierarchy_features`:\n",
    "   - Agrupa gêneros em clusters baseados em suas características de áudio.\n",
    "   Justificativa: Permite que o modelo capture similaridades entre gêneros que podem não ser evidentes apenas pelo nome.\n",
    "\n",
    "5. `create_genre_cooccurrence_features`:\n",
    "   - Cria features baseadas na co-ocorrência de gêneros para artistas.\n",
    "   Justificativa: Captura a versatilidade dos artistas e como isso pode afetar a popularidade.\n",
    "\n",
    "6. `create_genre_diversity_features`:\n",
    "   - Calcula a diversidade de gêneros para cada artista.\n",
    "   Justificativa: Mede o quão diversificado é o repertório de um artista, o que pode influenciar sua popularidade.\n",
    "\n",
    "7. `create_genre_crossover_score`:\n",
    "   - Calcula o quão típica uma música é para seu gênero declarado.\n",
    "   Justificativa: Músicas que se desviam significativamente das normas de seu gênero podem ter impactos únicos na popularidade.\n",
    "\n",
    "8. `create_safe_genre_features`:\n",
    "   - Cria features de gênero que são seguras de usar mesmo quando novos gêneros aparecem nos dados de teste.\n",
    "   Justificativa: Garante que o modelo possa lidar com gêneros não vistos durante o treinamento.\n",
    "\n",
    "9. `create_features`:\n",
    "   - Cria várias features derivadas, incluindo interações, razões e categorizações.\n",
    "   Justificativa: Fornece ao modelo mais informações derivadas que podem ser relevantes para prever popularidade.\n",
    "\n",
    "10. `treat_nan_values`:\n",
    "    - Preenche valores ausentes nas features.\n",
    "    Justificativa: Garante que todas as observações possam ser usadas no treinamento e previsão.\n",
    "\n",
    "Ao aplicar essas técnicas de engenharia de features, expandimos significativamente nosso conjunto de features. Isso permite que nosso modelo capture relações mais complexas e sutis nos dados, potencialmente melhorando sua capacidade de prever a popularidade das músicas com maior precisão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1326,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_audio_interactions(train_df, test_df):\n",
    "    audio_features = ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']\n",
    "    \n",
    "    for df in [train_df, test_df]:\n",
    "\n",
    "        df['energy_danceability'] = df['energy'] * df['danceability']\n",
    "        df['loudness_energy_ratio'] = df['loudness'] / (df['energy'] + 1e-5)\n",
    "        df['valence_energy_ratio'] = df['valence'] / (df['energy'] + 1e-5)\n",
    "        df['speechiness_instrumentalness_ratio'] = df['speechiness'] / (df['instrumentalness'] + 1e-5)\n",
    "        \n",
    "        df['intensity'] = (df['energy'] + df['loudness'] + df['tempo']) / 3\n",
    "        df['mellowness'] = (df['acousticness'] + df['instrumentalness'] + (1 - df['energy'])) / 3\n",
    "        df['complexity'] = (df['speechiness'] + df['instrumentalness'] + df['liveness']) / 3\n",
    "        \n",
    "        binner = KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='quantile')\n",
    "        binned_features = binner.fit_transform(df[audio_features])\n",
    "        \n",
    "        for i, feature in enumerate(audio_features):\n",
    "            df[f'{feature}_binned'] = binned_features[:, i]\n",
    "        \n",
    "        df['energy_danceability_binned'] = df['energy_binned'] * df['danceability_binned']\n",
    "        df['loudness_tempo_binned'] = df['loudness_binned'] * df['tempo_binned']\n",
    "\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1327,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_encoding(train_df, test_df, columns=['artists', 'album_name', 'track_genre']):\n",
    "\n",
    "    all_data = pd.concat([train_df, test_df], axis=0, ignore_index=True)\n",
    "    \n",
    "    for col in columns:\n",
    "        freq_enc = all_data[col].value_counts(normalize=True)\n",
    "        train_df[f'{col}_freq'] = train_df[col].map(freq_enc)\n",
    "        test_df[f'{col}_freq'] = test_df[col].map(freq_enc)\n",
    "        \n",
    "\n",
    "        min_freq = freq_enc.min()\n",
    "        train_df[f'{col}_freq'] = train_df[f'{col}_freq'].fillna(min_freq)\n",
    "        test_df[f'{col}_freq'] = test_df[f'{col}_freq'].fillna(min_freq)\n",
    "    \n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1328,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genre_popularity_encoding(train_df, test_df, target_column='popularity_target'):\n",
    "    \n",
    "    genre_stats = train_df.groupby('track_genre')[target_column].agg(['mean', 'median', 'std', 'count'])\n",
    "    genre_stats['popularity_percentile'] = genre_stats['mean'].rank(pct=True)\n",
    "    \n",
    "    def apply_encoding(df):\n",
    "\n",
    "        df['genre_mean_popularity'] = df['track_genre'].map(genre_stats['mean'])\n",
    "        \n",
    "        df['genre_median_popularity'] = df['track_genre'].map(genre_stats['median'])\n",
    "        \n",
    "        df['genre_popularity_percentile'] = df['track_genre'].map(genre_stats['popularity_percentile'])\n",
    "        \n",
    "        df['genre_popularity_variability'] = df['track_genre'].map(genre_stats['std'] / genre_stats['mean'])\n",
    "        \n",
    "        df['genre_track_count_log'] = df['track_genre'].map(np.log1p(genre_stats['count']))\n",
    "        \n",
    "        global_mean = genre_stats['mean'].mean()\n",
    "        global_median = genre_stats['median'].median()\n",
    "        global_percentile = 0.5  # middle percentile\n",
    "        global_variability = (genre_stats['std'] / genre_stats['mean']).mean()\n",
    "        global_count_log = np.log1p(genre_stats['count'].mean())\n",
    "        \n",
    "        df['genre_mean_popularity'] = df['genre_mean_popularity'].fillna(global_mean)\n",
    "        df['genre_median_popularity'] = df['genre_median_popularity'].fillna(global_median)\n",
    "        df['genre_popularity_percentile'] = df['genre_popularity_percentile'].fillna(global_percentile)\n",
    "        df['genre_popularity_variability'] = df['genre_popularity_variability'].fillna(global_variability)\n",
    "        df['genre_track_count_log'] = df['genre_track_count_log'].fillna(global_count_log)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    encoded_train = apply_encoding(train_df.copy())\n",
    "    encoded_test = apply_encoding(test_df.copy())\n",
    "    \n",
    "    return encoded_train, encoded_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1329,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_genre_hierarchy_features(train_df, test_df, n_clusters=10):\n",
    "\n",
    "    all_data = pd.concat([train_df, test_df], axis=0, ignore_index=True)\n",
    "    \n",
    "    audio_features = ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']\n",
    "    genre_features = all_data.groupby('track_genre')[audio_features].mean()\n",
    "    \n",
    "    clustering = AgglomerativeClustering(n_clusters=n_clusters)\n",
    "    genre_clusters = clustering.fit_predict(genre_features)\n",
    "    \n",
    "    genre_cluster_dict = dict(zip(genre_features.index, genre_clusters))\n",
    "    \n",
    "    for df in [train_df, test_df]:\n",
    "        df['genre_cluster'] = df['track_genre'].map(genre_cluster_dict)\n",
    "        \n",
    "        cluster_dummies = pd.get_dummies(df['genre_cluster'], prefix='genre_cluster')\n",
    "        df = pd.concat([df, cluster_dummies], axis=1)\n",
    "    \n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1330,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_genre_cooccurrence_features(train_df, test_df, n_components=10):\n",
    "\n",
    "    all_data = pd.concat([train_df, test_df], axis=0, ignore_index=True)\n",
    "    \n",
    "    artist_genres = all_data.groupby('artists')['track_genre'].apply(lambda x: ' '.join(set(x))).reset_index()\n",
    "    \n",
    "    vectorizer = CountVectorizer()\n",
    "    genre_matrix = vectorizer.fit_transform(artist_genres['track_genre'])\n",
    "    \n",
    "    svd = TruncatedSVD(n_components=n_components, random_state=42)\n",
    "    genre_cooccurrence = svd.fit_transform(genre_matrix)\n",
    "    \n",
    "    genres = vectorizer.get_feature_names_out()\n",
    "    genre_cooccur_dict = {genre: cooccur for genre, cooccur in zip(genres, genre_cooccurrence)}\n",
    "    \n",
    "    def safe_get_cooccur(genre):\n",
    "        cooccur = genre_cooccur_dict.get(genre)\n",
    "        if cooccur is None or np.isscalar(cooccur):\n",
    "            return np.zeros(n_components)\n",
    "        return cooccur\n",
    "    \n",
    "    for df in [train_df, test_df]:\n",
    "        cooccur_vectors = df['track_genre'].apply(safe_get_cooccur)\n",
    "        for i in range(n_components):\n",
    "            df[f'genre_cooccur_{i}'] = cooccur_vectors.apply(lambda x: x[i])\n",
    "    \n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1331,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_entropy(probabilities):\n",
    "\n",
    "    probabilities = probabilities[probabilities > 0]\n",
    "    return -np.sum(probabilities * np.log(probabilities))\n",
    "\n",
    "def create_genre_diversity_features(train_df, test_df):\n",
    "\n",
    "    all_data = pd.concat([train_df, test_df], axis=0, ignore_index=True)\n",
    "    \n",
    "    artist_genre_counts = all_data.groupby('artists')['track_genre'].value_counts().unstack(fill_value=0)\n",
    "    artist_genre_probs = normalize(artist_genre_counts, norm='l1', axis=1)\n",
    "    artist_genre_entropy = np.apply_along_axis(custom_entropy, 1, artist_genre_probs)\n",
    "    artist_genre_count = artist_genre_counts.sum(axis=1)\n",
    "    \n",
    "    artist_diversity_dict = dict(zip(artist_genre_counts.index, artist_genre_entropy))\n",
    "    artist_genre_count_dict = dict(zip(artist_genre_count.index, artist_genre_count.values))\n",
    "    \n",
    "    for df in [train_df, test_df]:\n",
    "        df['artist_genre_diversity'] = df['artists'].map(artist_diversity_dict)\n",
    "        df['artist_genre_count'] = df['artists'].map(artist_genre_count_dict)\n",
    "        df['artist_genre_diversity_ratio'] = df['artist_genre_diversity'] / np.log(df['artist_genre_count'])\n",
    "    \n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1332,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_genre_crossover_score(train_df, test_df):\n",
    "    audio_features = ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']\n",
    "    \n",
    "    genre_audio_avg = train_df.groupby('track_genre')[audio_features].mean()\n",
    "    \n",
    "    def calculate_crossover_score(row):\n",
    "        genre_avg = genre_audio_avg.loc[row['track_genre']]\n",
    "        return np.mean([abs(row[feat] - genre_avg[feat]) for feat in audio_features])\n",
    "    \n",
    "    for df in [train_df, test_df]:\n",
    "        df['genre_crossover_score'] = df.apply(calculate_crossover_score, axis=1)\n",
    "    \n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1333,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_safe_genre_features(train_df, test_df):\n",
    "\n",
    "    all_data = pd.concat([train_df, test_df], axis=0, ignore_index=True)\n",
    "    \n",
    "    audio_features = ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']\n",
    "    \n",
    "    genre_stats = all_data.groupby('track_genre')[audio_features].agg(['mean', 'std'])\n",
    "    genre_stats.columns = [f'genre_{col[0]}_{col[1]}' for col in genre_stats.columns]\n",
    "    \n",
    "    genre_freq = all_data['track_genre'].value_counts(normalize=True).to_dict()\n",
    "    \n",
    "    def apply_genre_encodings(df):\n",
    "\n",
    "        df = df.merge(genre_stats, on='track_genre', how='left')\n",
    "        \n",
    "        df['genre_frequency'] = df['track_genre'].map(genre_freq)\n",
    "        \n",
    "        for feature in audio_features:\n",
    "            df[f'{feature}_genre_deviation'] = df[feature] - df[f'genre_{feature}_mean']\n",
    "        \n",
    "        df['genre_typicality'] = np.mean([\n",
    "            1 - abs(df[f'{feature}_genre_deviation'] / df[f'genre_{feature}_std'])\n",
    "            for feature in audio_features\n",
    "        ], axis=0)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    train_df = apply_genre_encodings(train_df)\n",
    "    test_df = apply_genre_encodings(test_df)\n",
    "    \n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1334,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df):\n",
    "\n",
    "    df['energy_loudness_interaction'] = df['energy'] * df['loudness']\n",
    "    df['danceability_tempo_interaction'] = df['danceability'] * df['tempo']\n",
    "    df['acousticness_instrumentalness_interaction'] = df['acousticness'] * df['instrumentalness']\n",
    "\n",
    "    df['energy_danceability_ratio'] = df['energy'] / (df['danceability'] + 1e-5)\n",
    "    df['valence_arousal_ratio'] = df['valence'] / (np.sqrt(df['energy']**2 + df['danceability']**2) + 1e-5)\n",
    "\n",
    "    df['duration_minutes'] = df['duration_ms'] / 60000\n",
    "    df['duration_tempo_ratio'] = df['duration_minutes'] / (df['tempo'] + 1e-5)\n",
    "\n",
    "    df['audio_complexity'] = (df['instrumentalness'] + df['acousticness'] + df['speechiness']) / 3\n",
    "\n",
    "    audio_features = ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']\n",
    "    df['audio_feature_range'] = df[audio_features].max(axis=1) - df[audio_features].min(axis=1)\n",
    "\n",
    "    df['tempo_category'] = pd.cut(df['tempo'], bins=[0, 60, 90, 120, 150, np.inf], labels=[0, 1, 2, 3, 4])\n",
    "\n",
    "    df['key_mode_interaction'] = df['key'] * df['mode']\n",
    "\n",
    "    def custom_entropy(x):\n",
    "        probs = x.value_counts(normalize=True)\n",
    "        return -np.sum(probs * np.log2(probs + 1e-10))\n",
    "    \n",
    "    df['audio_feature_entropy'] = df[audio_features].apply(lambda x: custom_entropy(pd.cut(x, bins=10)), axis=1)\n",
    "\n",
    "    df['genre_encoded'] = df['track_genre'].astype('category').cat.codes\n",
    "\n",
    "    df['artist_encoded'] = df['artists'].astype('category').cat.codes\n",
    "\n",
    "    df['album_encoded'] = df['album_name'].astype('category').cat.codes\n",
    "\n",
    "    numerical_features = audio_features + ['duration_ms', 'key', 'time_signature']\n",
    "    scaler = StandardScaler()\n",
    "    df[numerical_features] = scaler.fit_transform(df[numerical_features])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1335,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treat_nan_values(df):\n",
    "\n",
    "    df_treated = df.copy()\n",
    "\n",
    "    numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
    "    non_numeric_columns = df.select_dtypes(exclude=[np.number]).columns\n",
    "    \n",
    "    for col in numeric_columns:\n",
    "        df_treated[col].fillna(df[col].median(), inplace=True)\n",
    "    \n",
    "    for col in non_numeric_columns:\n",
    "        df_treated[col].fillna(df[col].mode()[0], inplace=True)\n",
    "    \n",
    "    return df_treated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, criamos uma cópia da nossa base de dados e dropamos as colunas que não vamos usar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1336,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df_treating_data.copy()\n",
    "new_df = new_df.drop(columns=['track_unique_id', 'track_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, vamos aplicar a criação de novas features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df, test_df = create_audio_interactions(new_df, df_test)\n",
    "new_df, test_df = frequency_encoding(new_df, df_test)\n",
    "new_df, test_df = genre_popularity_encoding(new_df, test_df)\n",
    "new_df, test_df = create_genre_hierarchy_features(new_df, test_df)\n",
    "new_df, test_df = create_genre_cooccurrence_features(new_df, test_df)\n",
    "new_df, test_df = create_genre_diversity_features(new_df, test_df)\n",
    "new_df, test_df = create_safe_genre_features(new_df, test_df)\n",
    "new_df, test_df = create_genre_crossover_score(new_df, test_df)\n",
    "new_df = treat_nan_values(new_df)\n",
    "test_df = treat_nan_values(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui, codificamos tudo e já criamos os dicionários para usar depois com nossa base de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1338,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_df, encoding_dict, scaler_dict = normalize_and_encode_dataset(new_df, 'popularity_target')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com base de muito testes, as colunas abaixo são as melhores colunas para se excluir e manter a melhor acurária possível"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1339,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_df = encoded_df.drop(columns=['artists', 'album_name', 'track_name', 'duration_ms', 'explicit', 'danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'time_signature', 'track_genre', 'genre_mean_popularity_encoded_normalized', 'genre_median_popularity_encoded_normalized', 'genre_popularity_percentile_encoded_normalized', 'genre_popularity_variability_encoded_normalized', 'genre_track_count_log_encoded_normalized', 'artists_freq_encoded_normalized', 'album_name_freq_encoded_normalized', 'track_genre_freq_encoded_normalized', 'genre_cooccur_0_encoded_normalized','genre_cooccur_1_encoded_normalized','genre_cooccur_2_encoded_normalized','genre_cooccur_3_encoded_normalized','genre_cooccur_4_encoded_normalized','genre_cooccur_5_encoded_normalized','genre_cooccur_6_encoded_normalized','genre_cooccur_7_encoded_normalized','genre_cooccur_8_encoded_normalized','genre_cooccur_9_encoded_normalized', 'artist_genre_diversity_encoded_normalized','artist_genre_count_encoded_normalized','artist_genre_diversity_ratio_encoded_normalized', 'genre_cluster_encoded_normalized', 'genre_crossover_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, vamos separar nossa base de dados para começar os testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1340,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = encoded_df.drop('popularity_target', axis=1)\n",
    "y = encoded_df['popularity_target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_temp_df_no_genres, X_test_df_no_genres, y_temp_df_no_genres, y_test_df_no_genres = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_df_no_genres, X_val_df_no_genres, y_train_df_no_genres, y_val_df_no_genres = train_test_split(X_temp_df_no_genres, y_temp_df_no_genres, test_size=0.25, random_state=42)\n",
    "\n",
    "print(f\"Tamanho do conjunto de treino: {len(X_train_df_no_genres)}\")\n",
    "print(f\"Tamanho do conjunto de validação: {len(X_val_df_no_genres)}\")\n",
    "print(f\"Tamanho do conjunto de teste: {len(X_test_df_no_genres)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning de Hiperparâmetros\n",
    "\n",
    "O finetuning de hiperparâmetros é um processo crucial no desenvolvimento de modelos de machine learning. Ele envolve a otimização dos parâmetros que controlam o processo de aprendizagem do modelo, distintos dos parâmetros internos que o modelo aprende durante o treinamento.\n",
    "\n",
    "### Importância\n",
    "\n",
    "1. **Melhoria de Desempenho**: Hiperparâmetros bem ajustados podem melhorar significativamente a acurácia e generalização do modelo.\n",
    "2. **Prevenção de Overfitting**: Ajuda a encontrar o equilíbrio entre complexidade do modelo e capacidade de generalização.\n",
    "3. **Eficiência Computacional**: Otimiza o uso de recursos computacionais durante o treinamento.\n",
    "\n",
    "### Grid Search\n",
    "\n",
    "Grid Search é uma técnica de finetuning que envolve:\n",
    "\n",
    "1. Definição de um conjunto de valores possíveis para cada hiperparâmetro.\n",
    "2. Criação de todas as combinações possíveis desses valores.\n",
    "3. Treinamento e avaliação do modelo para cada combinação.\n",
    "4. Seleção da combinação que produz o melhor desempenho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "hgbc_param_grid = {\n",
    "    'max_iter': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_leaf': [1, 5, 10],\n",
    "    'max_bins': [255, 100, 50]\n",
    "}\n",
    "\n",
    "def perform_grid_search(classifier, param_grid, X_train, y_train):\n",
    "    grid_search = GridSearchCV(classifier, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    return grid_search\n",
    "\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "rf_grid_search = perform_grid_search(rf_classifier, rf_param_grid, X_train_df_no_genres, y_train_df_no_genres)\n",
    "\n",
    "hgb_classifier = HistGradientBoostingClassifier(random_state=42)\n",
    "hgb_grid_search = perform_grid_search(hgb_classifier, hgbc_param_grid, X_train_df_no_genres, y_train_df_no_genres)\n",
    "\n",
    "print(\"Random Forest Best Parameters:\")\n",
    "print(rf_grid_search.best_params_)\n",
    "print(\"Random Forest Best Accuracy:\", rf_grid_search.best_score_)\n",
    "\n",
    "print(\"\\nHistogram Gradient Boosting Best Parameters:\")\n",
    "print(hgb_grid_search.best_params_)\n",
    "print(\"Histogram Gradient Boosting Best Accuracy:\", hgb_grid_search.best_score_)\n",
    "\n",
    "rf_best = rf_grid_search.best_estimator_\n",
    "hgb_best = hgb_grid_search.best_estimator_\n",
    "\n",
    "rf_val_pred = rf_best.predict(X_val_df_no_genres)\n",
    "hgb_val_pred = hgb_best.predict(X_val_df_no_genres)\n",
    "\n",
    "print(\"\\nRandom Forest Validation Accuracy:\", accuracy_score(y_val_df_no_genres, rf_val_pred))\n",
    "print(\"Histogram Gradient Boosting Validation Accuracy:\", accuracy_score(y_val_df_no_genres, hgb_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "et_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "bc_param_grid = {\n",
    "    'n_estimators': [10, 50, 100],\n",
    "    'max_samples': [0.5, 0.7, 1.0],\n",
    "    'max_features': [0.5, 0.7, 1.0],\n",
    "    'bootstrap': [True, False],\n",
    "    'bootstrap_features': [True, False]\n",
    "}\n",
    "\n",
    "def perform_grid_search(classifier, param_grid, X_train, y_train):\n",
    "    grid_search = GridSearchCV(classifier, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    return grid_search\n",
    "\n",
    "classifiers = [\n",
    "    (\"Gradient Boosting\", GradientBoostingClassifier(random_state=42), gbc_param_grid),\n",
    "    (\"Extra Trees\", ExtraTreesClassifier(random_state=42), et_param_grid),\n",
    "    (\"Bagging\", BaggingClassifier(random_state=42), bc_param_grid)\n",
    "]\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, classifier, param_grid in classifiers:\n",
    "    print(f\"\\nPerforming grid search for {name}...\")\n",
    "    grid_search = perform_grid_search(classifier, param_grid, X_train_df_no_genres, y_train_df_no_genres)\n",
    "    results[name] = grid_search\n",
    "\n",
    "    print(f\"{name} Best Parameters:\")\n",
    "    print(grid_search.best_params_)\n",
    "    print(f\"{name} Best Accuracy:\", grid_search.best_score_)\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "    val_pred = best_model.predict(X_val_df_no_genres)\n",
    "    val_accuracy = accuracy_score(y_val_df_no_genres, val_pred)\n",
    "    print(f\"{name} Validation Accuracy:\", val_accuracy)\n",
    "\n",
    "print(\"\\nSummary of Results:\")\n",
    "for name, grid_search in results.items():\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  Best Parameters: {grid_search.best_params_}\")\n",
    "    print(f\"  Best Cross-validation Accuracy: {grid_search.best_score_:.4f}\")\n",
    "    best_model = grid_search.best_estimator_\n",
    "    val_pred = best_model.predict(X_val_df_no_genres)\n",
    "    val_accuracy = accuracy_score(y_val_df_no_genres, val_pred)\n",
    "    print(f\"  Validation Accuracy: {val_accuracy:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados do Finetuning de Hiperparâmetros\n",
    "\n",
    "| Modelo                         | Melhores Parâmetros                                                                                              | Acurácia CV | Acurácia Validação |\n",
    "|--------------------------------|------------------------------------------------------------------------------------------------------------------|-------------|---------------------|\n",
    "| Random Forest                  | max_depth: None<br>min_samples_leaf: 1<br>min_samples_split: 2<br>n_estimators: 300                              | 0.9213      | 0.9238              |\n",
    "| Histogram Gradient Boosting    | max_bins: 255<br>max_depth: 10<br>max_iter: 200<br>min_samples_leaf: 5                                           | 0.9192      | 0.9193              |\n",
    "| Gradient Boosting              | learning_rate: 0.1<br>max_depth: 7<br>min_samples_split: 10<br>n_estimators: 200                                 | 0.9216      | 0.9228              |\n",
    "| Extra Trees                    | max_depth: 30<br>min_samples_leaf: 1<br>min_samples_split: 5<br>n_estimators: 300                                | 0.9176      | 0.9212              |\n",
    "| Bagging                        | bootstrap: False<br>bootstrap_features: False<br>max_features: 0.7<br>max_samples: 0.7<br>n_estimators: 100      | 0.9219      | 0.9237              |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com o resultado, vamos criar nossos algoritmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1352,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier = RandomForestClassifier(max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=300, random_state=42)\n",
    "hist_gbc = HistGradientBoostingClassifier(max_bins=255, max_depth=10, max_iter=200, min_samples_leaf=5)\n",
    "gbc = GradientBoostingClassifier(learning_rate=0.1, max_depth=7, min_samples_split=10, n_estimators=200, random_state=42)\n",
    "et = ExtraTreesClassifier(max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=300, random_state=42)\n",
    "bc = BaggingClassifier(bootstrap=False, bootstrap_features=False, max_features=0.7, max_samples=0.7, n_estimators=100, random_state=42)\n",
    "mlp = MLPClassifier(activation='relu',alpha=0.0001,hidden_layer_sizes=(100,50), learning_rate='constant', solver='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Em busca da melhor `accuracy`\n",
    "\n",
    "O Weighted Voting Classifier é uma técnica de ensemble learning que combina as previsões de múltiplos modelos de machine learning para fazer uma previsão final. Na votação ponderada (weighted voting), cada modelo individual recebe um peso que determina sua influência na decisão final.\n",
    "\n",
    "#### Funcionamento\n",
    "\n",
    "1. **Combinação de Modelos**: Vários modelos são treinados independentemente nos mesmos dados.\n",
    "\n",
    "2. **Atribuição de Pesos**: Cada modelo recebe um peso baseado em sua confiabilidade ou performance.\n",
    "\n",
    "3. **Votação Soft**: No modo 'soft', cada classificador fornece uma probabilidade para cada classe, em vez de apenas uma previsão de classe.\n",
    "\n",
    "4. **Agregação Ponderada**: As probabilidades de cada modelo são multiplicadas por seus respectivos pesos e somadas.\n",
    "\n",
    "5. **Decisão Final**: A classe com a maior soma ponderada de probabilidades é escolhida como a previsão final.\n",
    "\n",
    "#### Vantagens\n",
    "\n",
    "1. **Melhoria da Acurácia**: Combina as forças de diferentes modelos, potencialmente superando o desempenho de qualquer modelo individual.\n",
    "2. **Redução de Overfitting**: A agregação de múltiplos modelos pode ajudar a reduzir o overfitting.\n",
    "3. **Robustez**: Menos sensível a outliers ou dados ruidosos comparado a modelos individuais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('hist_gbc', hist_gbc),\n",
    "        ('rf_classifier', rf_classifier),\n",
    "        ('gbc', gbc),\n",
    "        ('et', et),\n",
    "        ('bc', bc),\n",
    "    ],\n",
    "    voting='soft',\n",
    "    weights=[1, 1, 1, 2, 3]\n",
    ")\n",
    "\n",
    "weighted_voting_clf.fit(X_train_df_no_genres, y_train_df_no_genres)\n",
    "y_pred_val = weighted_voting_clf.predict(X_val_df_no_genres)\n",
    "y_pred_test = weighted_voting_clf.predict(X_test_df_no_genres)\n",
    "\n",
    "print(\"Weighted Voting Classifier - Validation Accuracy:\", accuracy_score(y_val_df_no_genres, y_pred_val))\n",
    "print(\"Weighted Voting Classifier - Test Accuracy:\", accuracy_score(y_test_df_no_genres, y_pred_test))\n",
    "print(\"Weighted Voting Classifier - Validation Accuracy:\", classification_report(y_val_df_no_genres, y_pred_val))\n",
    "print(\"Weighted Voting Classifier - Test Accuracy:\", classification_report(y_test_df_no_genres, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Análise Geral\n",
    "\n",
    "1. **Consistência**: As métricas são consistentes entre os conjuntos de validação e teste, indicando boa generalização do modelo.\n",
    "\n",
    "2. **Equilíbrio de Classes**: O desempenho é equilibrado entre as classes 0 e 1, sugerindo que o modelo não é enviesado para uma classe específica.\n",
    "\n",
    "3. **Alto Desempenho**: Todas as métricas estão acima de 0.92, indicando um excelente desempenho geral do modelo.\n",
    "\n",
    "4. **Robustez**: A pequena diferença entre as métricas de validação e teste (menos de 0.5 pontos percentuais) sugere que o modelo é robusto e não está sofrendo de overfitting significativo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos aplicar tudo o que aplicamos no base de treino, para a base de testes. Depois salvar o resultado em CSV e fazer o envio da atividade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1355,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_target_encoding = test_df.copy()\n",
    "df_test_target_encoding = df_test_target_encoding.drop(columns=['track_unique_id', 'track_id'])\n",
    "\n",
    "df_test_target_encoding['tempo'] = df_test_target_encoding['tempo'].replace(0,tempo_median)\n",
    "df_test_target_encoding['time_signature'] = df_test_target_encoding['time_signature'].replace(0,4)\n",
    "\n",
    "df_test_target_encoding = apply_normalize_and_encode(df_test_target_encoding, encoding_dict, scaler_dict)\n",
    "\n",
    "df_test_target_encoding = df_test_target_encoding.drop(columns=['artists', 'album_name', 'track_name', 'duration_ms', 'explicit', 'danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'time_signature', 'track_genre', 'genre_mean_popularity_encoded_normalized', 'genre_median_popularity_encoded_normalized', 'genre_popularity_percentile_encoded_normalized', 'genre_popularity_variability_encoded_normalized', 'genre_track_count_log_encoded_normalized', 'artists_freq_encoded_normalized', 'album_name_freq_encoded_normalized', 'track_genre_freq_encoded_normalized', 'genre_cooccur_0_encoded_normalized','genre_cooccur_1_encoded_normalized','genre_cooccur_2_encoded_normalized','genre_cooccur_3_encoded_normalized','genre_cooccur_4_encoded_normalized','genre_cooccur_5_encoded_normalized','genre_cooccur_6_encoded_normalized','genre_cooccur_7_encoded_normalized','genre_cooccur_8_encoded_normalized','genre_cooccur_9_encoded_normalized', 'artist_genre_diversity_encoded_normalized','artist_genre_count_encoded_normalized','artist_genre_diversity_ratio_encoded_normalized', 'genre_cluster_encoded_normalized', 'genre_crossover_score'])\n",
    "\n",
    "predict_target_encoding_stacking = weighted_voting_clf.predict(df_test_target_encoding)\n",
    "result_stacking = pd.DataFrame({ 'track_unique_id': df_test['track_unique_id'], 'popularity_target': predict_target_encoding_stacking })\n",
    "result_stacking.to_csv('result_weighed_11123.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
